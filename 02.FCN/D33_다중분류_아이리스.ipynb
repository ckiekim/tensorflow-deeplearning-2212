{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 다중분류 - 아이리스"
      ],
      "metadata": {
        "id": "NdcatkPABlOX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PNpb_CU3BgXE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "seed = 2023\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터 전처리"
      ],
      "metadata": {
        "id": "4poylEiABwH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "WoQK_cPKBsGW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "iris_std = StandardScaler().fit_transform(iris.data)"
      ],
      "metadata": {
        "id": "esG3xg0MCMOX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_onehot = to_categorical(iris.target)\n",
        "y_onehot.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2CCdsikCpBt",
        "outputId": "6baa7606-6ceb-4119-873e-8f623a9a1c11"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_onehot[0], y_onehot[50], y_onehot[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4PXpcXADGbv",
        "outputId": "8d2b4fbf-c997-479b-f4bf-36559d996f9e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 0., 0.], dtype=float32),\n",
              " array([0., 1., 0.], dtype=float32),\n",
              " array([0., 0., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    iris_std, y_onehot, stratify=y_onehot, test_size=0.2, random_state=seed\n",
        ")"
      ],
      "metadata": {
        "id": "2qsafw6kDNFe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 정의/설정/학습/평가"
      ],
      "metadata": {
        "id": "Ghf0vj3HD_Cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "Gj962JKMDw3B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 정의\n",
        "    - 출력층의 노드 갯수와 활성화 함수"
      ],
      "metadata": {
        "id": "CA7NvIiIEbZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([ \n",
        "    Dense(12, input_dim=4, activation='relu'),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxmnryG8EWW-",
        "outputId": "e03132e0-1d9c-4297-dc4c-8f5bd796525b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                60        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 191\n",
            "Trainable params: 191\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 설정\n",
        "    - loss 함수: categorical crossentropy"
      ],
      "metadata": {
        "id": "g58SI8Q8FNMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "IVD2mRztFFbo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 콜백 함수 정리 후 학습"
      ],
      "metadata": {
        "id": "gGQlfpXlFndy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'best_model.h5'\n",
        "mc = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
        "es = EarlyStopping(monitor='val_loss', patience=20)\n",
        "hist = model.fit(X_train, Y_train, validation_split=0.2,\n",
        "                   epochs=2000, batch_size=100, verbose=0, \n",
        "                   callbacks=[mc, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0lEUgcRFjrg",
        "outputId": "54bbc0ce-6e57-490c-c239-28072c6e155a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 1.16358, saving model to best_model.h5\n",
            "\n",
            "Epoch 2: val_loss improved from 1.16358 to 1.15359, saving model to best_model.h5\n",
            "\n",
            "Epoch 3: val_loss improved from 1.15359 to 1.14372, saving model to best_model.h5\n",
            "\n",
            "Epoch 4: val_loss improved from 1.14372 to 1.13397, saving model to best_model.h5\n",
            "\n",
            "Epoch 5: val_loss improved from 1.13397 to 1.12434, saving model to best_model.h5\n",
            "\n",
            "Epoch 6: val_loss improved from 1.12434 to 1.11483, saving model to best_model.h5\n",
            "\n",
            "Epoch 7: val_loss improved from 1.11483 to 1.10543, saving model to best_model.h5\n",
            "\n",
            "Epoch 8: val_loss improved from 1.10543 to 1.09615, saving model to best_model.h5\n",
            "\n",
            "Epoch 9: val_loss improved from 1.09615 to 1.08700, saving model to best_model.h5\n",
            "\n",
            "Epoch 10: val_loss improved from 1.08700 to 1.07796, saving model to best_model.h5\n",
            "\n",
            "Epoch 11: val_loss improved from 1.07796 to 1.06905, saving model to best_model.h5\n",
            "\n",
            "Epoch 12: val_loss improved from 1.06905 to 1.06025, saving model to best_model.h5\n",
            "\n",
            "Epoch 13: val_loss improved from 1.06025 to 1.05158, saving model to best_model.h5\n",
            "\n",
            "Epoch 14: val_loss improved from 1.05158 to 1.04303, saving model to best_model.h5\n",
            "\n",
            "Epoch 15: val_loss improved from 1.04303 to 1.03459, saving model to best_model.h5\n",
            "\n",
            "Epoch 16: val_loss improved from 1.03459 to 1.02627, saving model to best_model.h5\n",
            "\n",
            "Epoch 17: val_loss improved from 1.02627 to 1.01807, saving model to best_model.h5\n",
            "\n",
            "Epoch 18: val_loss improved from 1.01807 to 1.00996, saving model to best_model.h5\n",
            "\n",
            "Epoch 19: val_loss improved from 1.00996 to 1.00196, saving model to best_model.h5\n",
            "\n",
            "Epoch 20: val_loss improved from 1.00196 to 0.99404, saving model to best_model.h5\n",
            "\n",
            "Epoch 21: val_loss improved from 0.99404 to 0.98620, saving model to best_model.h5\n",
            "\n",
            "Epoch 22: val_loss improved from 0.98620 to 0.97845, saving model to best_model.h5\n",
            "\n",
            "Epoch 23: val_loss improved from 0.97845 to 0.97077, saving model to best_model.h5\n",
            "\n",
            "Epoch 24: val_loss improved from 0.97077 to 0.96319, saving model to best_model.h5\n",
            "\n",
            "Epoch 25: val_loss improved from 0.96319 to 0.95568, saving model to best_model.h5\n",
            "\n",
            "Epoch 26: val_loss improved from 0.95568 to 0.94825, saving model to best_model.h5\n",
            "\n",
            "Epoch 27: val_loss improved from 0.94825 to 0.94091, saving model to best_model.h5\n",
            "\n",
            "Epoch 28: val_loss improved from 0.94091 to 0.93366, saving model to best_model.h5\n",
            "\n",
            "Epoch 29: val_loss improved from 0.93366 to 0.92647, saving model to best_model.h5\n",
            "\n",
            "Epoch 30: val_loss improved from 0.92647 to 0.91935, saving model to best_model.h5\n",
            "\n",
            "Epoch 31: val_loss improved from 0.91935 to 0.91230, saving model to best_model.h5\n",
            "\n",
            "Epoch 32: val_loss improved from 0.91230 to 0.90530, saving model to best_model.h5\n",
            "\n",
            "Epoch 33: val_loss improved from 0.90530 to 0.89842, saving model to best_model.h5\n",
            "\n",
            "Epoch 34: val_loss improved from 0.89842 to 0.89165, saving model to best_model.h5\n",
            "\n",
            "Epoch 35: val_loss improved from 0.89165 to 0.88494, saving model to best_model.h5\n",
            "\n",
            "Epoch 36: val_loss improved from 0.88494 to 0.87827, saving model to best_model.h5\n",
            "\n",
            "Epoch 37: val_loss improved from 0.87827 to 0.87166, saving model to best_model.h5\n",
            "\n",
            "Epoch 38: val_loss improved from 0.87166 to 0.86509, saving model to best_model.h5\n",
            "\n",
            "Epoch 39: val_loss improved from 0.86509 to 0.85858, saving model to best_model.h5\n",
            "\n",
            "Epoch 40: val_loss improved from 0.85858 to 0.85214, saving model to best_model.h5\n",
            "\n",
            "Epoch 41: val_loss improved from 0.85214 to 0.84580, saving model to best_model.h5\n",
            "\n",
            "Epoch 42: val_loss improved from 0.84580 to 0.83949, saving model to best_model.h5\n",
            "\n",
            "Epoch 43: val_loss improved from 0.83949 to 0.83322, saving model to best_model.h5\n",
            "\n",
            "Epoch 44: val_loss improved from 0.83322 to 0.82702, saving model to best_model.h5\n",
            "\n",
            "Epoch 45: val_loss improved from 0.82702 to 0.82090, saving model to best_model.h5\n",
            "\n",
            "Epoch 46: val_loss improved from 0.82090 to 0.81481, saving model to best_model.h5\n",
            "\n",
            "Epoch 47: val_loss improved from 0.81481 to 0.80875, saving model to best_model.h5\n",
            "\n",
            "Epoch 48: val_loss improved from 0.80875 to 0.80274, saving model to best_model.h5\n",
            "\n",
            "Epoch 49: val_loss improved from 0.80274 to 0.79677, saving model to best_model.h5\n",
            "\n",
            "Epoch 50: val_loss improved from 0.79677 to 0.79084, saving model to best_model.h5\n",
            "\n",
            "Epoch 51: val_loss improved from 0.79084 to 0.78494, saving model to best_model.h5\n",
            "\n",
            "Epoch 52: val_loss improved from 0.78494 to 0.77906, saving model to best_model.h5\n",
            "\n",
            "Epoch 53: val_loss improved from 0.77906 to 0.77318, saving model to best_model.h5\n",
            "\n",
            "Epoch 54: val_loss improved from 0.77318 to 0.76732, saving model to best_model.h5\n",
            "\n",
            "Epoch 55: val_loss improved from 0.76732 to 0.76150, saving model to best_model.h5\n",
            "\n",
            "Epoch 56: val_loss improved from 0.76150 to 0.75571, saving model to best_model.h5\n",
            "\n",
            "Epoch 57: val_loss improved from 0.75571 to 0.74996, saving model to best_model.h5\n",
            "\n",
            "Epoch 58: val_loss improved from 0.74996 to 0.74423, saving model to best_model.h5\n",
            "\n",
            "Epoch 59: val_loss improved from 0.74423 to 0.73854, saving model to best_model.h5\n",
            "\n",
            "Epoch 60: val_loss improved from 0.73854 to 0.73289, saving model to best_model.h5\n",
            "\n",
            "Epoch 61: val_loss improved from 0.73289 to 0.72727, saving model to best_model.h5\n",
            "\n",
            "Epoch 62: val_loss improved from 0.72727 to 0.72170, saving model to best_model.h5\n",
            "\n",
            "Epoch 63: val_loss improved from 0.72170 to 0.71616, saving model to best_model.h5\n",
            "\n",
            "Epoch 64: val_loss improved from 0.71616 to 0.71068, saving model to best_model.h5\n",
            "\n",
            "Epoch 65: val_loss improved from 0.71068 to 0.70523, saving model to best_model.h5\n",
            "\n",
            "Epoch 66: val_loss improved from 0.70523 to 0.69983, saving model to best_model.h5\n",
            "\n",
            "Epoch 67: val_loss improved from 0.69983 to 0.69447, saving model to best_model.h5\n",
            "\n",
            "Epoch 68: val_loss improved from 0.69447 to 0.68915, saving model to best_model.h5\n",
            "\n",
            "Epoch 69: val_loss improved from 0.68915 to 0.68387, saving model to best_model.h5\n",
            "\n",
            "Epoch 70: val_loss improved from 0.68387 to 0.67864, saving model to best_model.h5\n",
            "\n",
            "Epoch 71: val_loss improved from 0.67864 to 0.67346, saving model to best_model.h5\n",
            "\n",
            "Epoch 72: val_loss improved from 0.67346 to 0.66832, saving model to best_model.h5\n",
            "\n",
            "Epoch 73: val_loss improved from 0.66832 to 0.66322, saving model to best_model.h5\n",
            "\n",
            "Epoch 74: val_loss improved from 0.66322 to 0.65817, saving model to best_model.h5\n",
            "\n",
            "Epoch 75: val_loss improved from 0.65817 to 0.65317, saving model to best_model.h5\n",
            "\n",
            "Epoch 76: val_loss improved from 0.65317 to 0.64821, saving model to best_model.h5\n",
            "\n",
            "Epoch 77: val_loss improved from 0.64821 to 0.64331, saving model to best_model.h5\n",
            "\n",
            "Epoch 78: val_loss improved from 0.64331 to 0.63845, saving model to best_model.h5\n",
            "\n",
            "Epoch 79: val_loss improved from 0.63845 to 0.63365, saving model to best_model.h5\n",
            "\n",
            "Epoch 80: val_loss improved from 0.63365 to 0.62890, saving model to best_model.h5\n",
            "\n",
            "Epoch 81: val_loss improved from 0.62890 to 0.62422, saving model to best_model.h5\n",
            "\n",
            "Epoch 82: val_loss improved from 0.62422 to 0.61959, saving model to best_model.h5\n",
            "\n",
            "Epoch 83: val_loss improved from 0.61959 to 0.61502, saving model to best_model.h5\n",
            "\n",
            "Epoch 84: val_loss improved from 0.61502 to 0.61051, saving model to best_model.h5\n",
            "\n",
            "Epoch 85: val_loss improved from 0.61051 to 0.60609, saving model to best_model.h5\n",
            "\n",
            "Epoch 86: val_loss improved from 0.60609 to 0.60174, saving model to best_model.h5\n",
            "\n",
            "Epoch 87: val_loss improved from 0.60174 to 0.59744, saving model to best_model.h5\n",
            "\n",
            "Epoch 88: val_loss improved from 0.59744 to 0.59321, saving model to best_model.h5\n",
            "\n",
            "Epoch 89: val_loss improved from 0.59321 to 0.58903, saving model to best_model.h5\n",
            "\n",
            "Epoch 90: val_loss improved from 0.58903 to 0.58491, saving model to best_model.h5\n",
            "\n",
            "Epoch 91: val_loss improved from 0.58491 to 0.58084, saving model to best_model.h5\n",
            "\n",
            "Epoch 92: val_loss improved from 0.58084 to 0.57679, saving model to best_model.h5\n",
            "\n",
            "Epoch 93: val_loss improved from 0.57679 to 0.57277, saving model to best_model.h5\n",
            "\n",
            "Epoch 94: val_loss improved from 0.57277 to 0.56881, saving model to best_model.h5\n",
            "\n",
            "Epoch 95: val_loss improved from 0.56881 to 0.56490, saving model to best_model.h5\n",
            "\n",
            "Epoch 96: val_loss improved from 0.56490 to 0.56103, saving model to best_model.h5\n",
            "\n",
            "Epoch 97: val_loss improved from 0.56103 to 0.55722, saving model to best_model.h5\n",
            "\n",
            "Epoch 98: val_loss improved from 0.55722 to 0.55346, saving model to best_model.h5\n",
            "\n",
            "Epoch 99: val_loss improved from 0.55346 to 0.54978, saving model to best_model.h5\n",
            "\n",
            "Epoch 100: val_loss improved from 0.54978 to 0.54616, saving model to best_model.h5\n",
            "\n",
            "Epoch 101: val_loss improved from 0.54616 to 0.54261, saving model to best_model.h5\n",
            "\n",
            "Epoch 102: val_loss improved from 0.54261 to 0.53910, saving model to best_model.h5\n",
            "\n",
            "Epoch 103: val_loss improved from 0.53910 to 0.53564, saving model to best_model.h5\n",
            "\n",
            "Epoch 104: val_loss improved from 0.53564 to 0.53222, saving model to best_model.h5\n",
            "\n",
            "Epoch 105: val_loss improved from 0.53222 to 0.52884, saving model to best_model.h5\n",
            "\n",
            "Epoch 106: val_loss improved from 0.52884 to 0.52551, saving model to best_model.h5\n",
            "\n",
            "Epoch 107: val_loss improved from 0.52551 to 0.52223, saving model to best_model.h5\n",
            "\n",
            "Epoch 108: val_loss improved from 0.52223 to 0.51899, saving model to best_model.h5\n",
            "\n",
            "Epoch 109: val_loss improved from 0.51899 to 0.51578, saving model to best_model.h5\n",
            "\n",
            "Epoch 110: val_loss improved from 0.51578 to 0.51261, saving model to best_model.h5\n",
            "\n",
            "Epoch 111: val_loss improved from 0.51261 to 0.50947, saving model to best_model.h5\n",
            "\n",
            "Epoch 112: val_loss improved from 0.50947 to 0.50636, saving model to best_model.h5\n",
            "\n",
            "Epoch 113: val_loss improved from 0.50636 to 0.50329, saving model to best_model.h5\n",
            "\n",
            "Epoch 114: val_loss improved from 0.50329 to 0.50026, saving model to best_model.h5\n",
            "\n",
            "Epoch 115: val_loss improved from 0.50026 to 0.49726, saving model to best_model.h5\n",
            "\n",
            "Epoch 116: val_loss improved from 0.49726 to 0.49430, saving model to best_model.h5\n",
            "\n",
            "Epoch 117: val_loss improved from 0.49430 to 0.49138, saving model to best_model.h5\n",
            "\n",
            "Epoch 118: val_loss improved from 0.49138 to 0.48849, saving model to best_model.h5\n",
            "\n",
            "Epoch 119: val_loss improved from 0.48849 to 0.48564, saving model to best_model.h5\n",
            "\n",
            "Epoch 120: val_loss improved from 0.48564 to 0.48282, saving model to best_model.h5\n",
            "\n",
            "Epoch 121: val_loss improved from 0.48282 to 0.48003, saving model to best_model.h5\n",
            "\n",
            "Epoch 122: val_loss improved from 0.48003 to 0.47729, saving model to best_model.h5\n",
            "\n",
            "Epoch 123: val_loss improved from 0.47729 to 0.47458, saving model to best_model.h5\n",
            "\n",
            "Epoch 124: val_loss improved from 0.47458 to 0.47191, saving model to best_model.h5\n",
            "\n",
            "Epoch 125: val_loss improved from 0.47191 to 0.46926, saving model to best_model.h5\n",
            "\n",
            "Epoch 126: val_loss improved from 0.46926 to 0.46664, saving model to best_model.h5\n",
            "\n",
            "Epoch 127: val_loss improved from 0.46664 to 0.46404, saving model to best_model.h5\n",
            "\n",
            "Epoch 128: val_loss improved from 0.46404 to 0.46147, saving model to best_model.h5\n",
            "\n",
            "Epoch 129: val_loss improved from 0.46147 to 0.45893, saving model to best_model.h5\n",
            "\n",
            "Epoch 130: val_loss improved from 0.45893 to 0.45641, saving model to best_model.h5\n",
            "\n",
            "Epoch 131: val_loss improved from 0.45641 to 0.45392, saving model to best_model.h5\n",
            "\n",
            "Epoch 132: val_loss improved from 0.45392 to 0.45146, saving model to best_model.h5\n",
            "\n",
            "Epoch 133: val_loss improved from 0.45146 to 0.44903, saving model to best_model.h5\n",
            "\n",
            "Epoch 134: val_loss improved from 0.44903 to 0.44662, saving model to best_model.h5\n",
            "\n",
            "Epoch 135: val_loss improved from 0.44662 to 0.44423, saving model to best_model.h5\n",
            "\n",
            "Epoch 136: val_loss improved from 0.44423 to 0.44187, saving model to best_model.h5\n",
            "\n",
            "Epoch 137: val_loss improved from 0.44187 to 0.43954, saving model to best_model.h5\n",
            "\n",
            "Epoch 138: val_loss improved from 0.43954 to 0.43724, saving model to best_model.h5\n",
            "\n",
            "Epoch 139: val_loss improved from 0.43724 to 0.43496, saving model to best_model.h5\n",
            "\n",
            "Epoch 140: val_loss improved from 0.43496 to 0.43271, saving model to best_model.h5\n",
            "\n",
            "Epoch 141: val_loss improved from 0.43271 to 0.43048, saving model to best_model.h5\n",
            "\n",
            "Epoch 142: val_loss improved from 0.43048 to 0.42827, saving model to best_model.h5\n",
            "\n",
            "Epoch 143: val_loss improved from 0.42827 to 0.42608, saving model to best_model.h5\n",
            "\n",
            "Epoch 144: val_loss improved from 0.42608 to 0.42391, saving model to best_model.h5\n",
            "\n",
            "Epoch 145: val_loss improved from 0.42391 to 0.42176, saving model to best_model.h5\n",
            "\n",
            "Epoch 146: val_loss improved from 0.42176 to 0.41964, saving model to best_model.h5\n",
            "\n",
            "Epoch 147: val_loss improved from 0.41964 to 0.41754, saving model to best_model.h5\n",
            "\n",
            "Epoch 148: val_loss improved from 0.41754 to 0.41545, saving model to best_model.h5\n",
            "\n",
            "Epoch 149: val_loss improved from 0.41545 to 0.41339, saving model to best_model.h5\n",
            "\n",
            "Epoch 150: val_loss improved from 0.41339 to 0.41135, saving model to best_model.h5\n",
            "\n",
            "Epoch 151: val_loss improved from 0.41135 to 0.40933, saving model to best_model.h5\n",
            "\n",
            "Epoch 152: val_loss improved from 0.40933 to 0.40732, saving model to best_model.h5\n",
            "\n",
            "Epoch 153: val_loss improved from 0.40732 to 0.40533, saving model to best_model.h5\n",
            "\n",
            "Epoch 154: val_loss improved from 0.40533 to 0.40335, saving model to best_model.h5\n",
            "\n",
            "Epoch 155: val_loss improved from 0.40335 to 0.40138, saving model to best_model.h5\n",
            "\n",
            "Epoch 156: val_loss improved from 0.40138 to 0.39942, saving model to best_model.h5\n",
            "\n",
            "Epoch 157: val_loss improved from 0.39942 to 0.39746, saving model to best_model.h5\n",
            "\n",
            "Epoch 158: val_loss improved from 0.39746 to 0.39552, saving model to best_model.h5\n",
            "\n",
            "Epoch 159: val_loss improved from 0.39552 to 0.39358, saving model to best_model.h5\n",
            "\n",
            "Epoch 160: val_loss improved from 0.39358 to 0.39166, saving model to best_model.h5\n",
            "\n",
            "Epoch 161: val_loss improved from 0.39166 to 0.38976, saving model to best_model.h5\n",
            "\n",
            "Epoch 162: val_loss improved from 0.38976 to 0.38787, saving model to best_model.h5\n",
            "\n",
            "Epoch 163: val_loss improved from 0.38787 to 0.38599, saving model to best_model.h5\n",
            "\n",
            "Epoch 164: val_loss improved from 0.38599 to 0.38412, saving model to best_model.h5\n",
            "\n",
            "Epoch 165: val_loss improved from 0.38412 to 0.38226, saving model to best_model.h5\n",
            "\n",
            "Epoch 166: val_loss improved from 0.38226 to 0.38041, saving model to best_model.h5\n",
            "\n",
            "Epoch 167: val_loss improved from 0.38041 to 0.37857, saving model to best_model.h5\n",
            "\n",
            "Epoch 168: val_loss improved from 0.37857 to 0.37671, saving model to best_model.h5\n",
            "\n",
            "Epoch 169: val_loss improved from 0.37671 to 0.37486, saving model to best_model.h5\n",
            "\n",
            "Epoch 170: val_loss improved from 0.37486 to 0.37301, saving model to best_model.h5\n",
            "\n",
            "Epoch 171: val_loss improved from 0.37301 to 0.37118, saving model to best_model.h5\n",
            "\n",
            "Epoch 172: val_loss improved from 0.37118 to 0.36935, saving model to best_model.h5\n",
            "\n",
            "Epoch 173: val_loss improved from 0.36935 to 0.36744, saving model to best_model.h5\n",
            "\n",
            "Epoch 174: val_loss improved from 0.36744 to 0.36553, saving model to best_model.h5\n",
            "\n",
            "Epoch 175: val_loss improved from 0.36553 to 0.36363, saving model to best_model.h5\n",
            "\n",
            "Epoch 176: val_loss improved from 0.36363 to 0.36174, saving model to best_model.h5\n",
            "\n",
            "Epoch 177: val_loss improved from 0.36174 to 0.35985, saving model to best_model.h5\n",
            "\n",
            "Epoch 178: val_loss improved from 0.35985 to 0.35797, saving model to best_model.h5\n",
            "\n",
            "Epoch 179: val_loss improved from 0.35797 to 0.35609, saving model to best_model.h5\n",
            "\n",
            "Epoch 180: val_loss improved from 0.35609 to 0.35423, saving model to best_model.h5\n",
            "\n",
            "Epoch 181: val_loss improved from 0.35423 to 0.35237, saving model to best_model.h5\n",
            "\n",
            "Epoch 182: val_loss improved from 0.35237 to 0.35051, saving model to best_model.h5\n",
            "\n",
            "Epoch 183: val_loss improved from 0.35051 to 0.34865, saving model to best_model.h5\n",
            "\n",
            "Epoch 184: val_loss improved from 0.34865 to 0.34680, saving model to best_model.h5\n",
            "\n",
            "Epoch 185: val_loss improved from 0.34680 to 0.34495, saving model to best_model.h5\n",
            "\n",
            "Epoch 186: val_loss improved from 0.34495 to 0.34311, saving model to best_model.h5\n",
            "\n",
            "Epoch 187: val_loss improved from 0.34311 to 0.34128, saving model to best_model.h5\n",
            "\n",
            "Epoch 188: val_loss improved from 0.34128 to 0.33945, saving model to best_model.h5\n",
            "\n",
            "Epoch 189: val_loss improved from 0.33945 to 0.33764, saving model to best_model.h5\n",
            "\n",
            "Epoch 190: val_loss improved from 0.33764 to 0.33589, saving model to best_model.h5\n",
            "\n",
            "Epoch 191: val_loss improved from 0.33589 to 0.33413, saving model to best_model.h5\n",
            "\n",
            "Epoch 192: val_loss improved from 0.33413 to 0.33239, saving model to best_model.h5\n",
            "\n",
            "Epoch 193: val_loss improved from 0.33239 to 0.33064, saving model to best_model.h5\n",
            "\n",
            "Epoch 194: val_loss improved from 0.33064 to 0.32891, saving model to best_model.h5\n",
            "\n",
            "Epoch 195: val_loss improved from 0.32891 to 0.32720, saving model to best_model.h5\n",
            "\n",
            "Epoch 196: val_loss improved from 0.32720 to 0.32550, saving model to best_model.h5\n",
            "\n",
            "Epoch 197: val_loss improved from 0.32550 to 0.32380, saving model to best_model.h5\n",
            "\n",
            "Epoch 198: val_loss improved from 0.32380 to 0.32210, saving model to best_model.h5\n",
            "\n",
            "Epoch 199: val_loss improved from 0.32210 to 0.32040, saving model to best_model.h5\n",
            "\n",
            "Epoch 200: val_loss improved from 0.32040 to 0.31871, saving model to best_model.h5\n",
            "\n",
            "Epoch 201: val_loss improved from 0.31871 to 0.31701, saving model to best_model.h5\n",
            "\n",
            "Epoch 202: val_loss improved from 0.31701 to 0.31533, saving model to best_model.h5\n",
            "\n",
            "Epoch 203: val_loss improved from 0.31533 to 0.31364, saving model to best_model.h5\n",
            "\n",
            "Epoch 204: val_loss improved from 0.31364 to 0.31196, saving model to best_model.h5\n",
            "\n",
            "Epoch 205: val_loss improved from 0.31196 to 0.31028, saving model to best_model.h5\n",
            "\n",
            "Epoch 206: val_loss improved from 0.31028 to 0.30861, saving model to best_model.h5\n",
            "\n",
            "Epoch 207: val_loss improved from 0.30861 to 0.30694, saving model to best_model.h5\n",
            "\n",
            "Epoch 208: val_loss improved from 0.30694 to 0.30528, saving model to best_model.h5\n",
            "\n",
            "Epoch 209: val_loss improved from 0.30528 to 0.30362, saving model to best_model.h5\n",
            "\n",
            "Epoch 210: val_loss improved from 0.30362 to 0.30197, saving model to best_model.h5\n",
            "\n",
            "Epoch 211: val_loss improved from 0.30197 to 0.30033, saving model to best_model.h5\n",
            "\n",
            "Epoch 212: val_loss improved from 0.30033 to 0.29869, saving model to best_model.h5\n",
            "\n",
            "Epoch 213: val_loss improved from 0.29869 to 0.29706, saving model to best_model.h5\n",
            "\n",
            "Epoch 214: val_loss improved from 0.29706 to 0.29544, saving model to best_model.h5\n",
            "\n",
            "Epoch 215: val_loss improved from 0.29544 to 0.29383, saving model to best_model.h5\n",
            "\n",
            "Epoch 216: val_loss improved from 0.29383 to 0.29223, saving model to best_model.h5\n",
            "\n",
            "Epoch 217: val_loss improved from 0.29223 to 0.29063, saving model to best_model.h5\n",
            "\n",
            "Epoch 218: val_loss improved from 0.29063 to 0.28904, saving model to best_model.h5\n",
            "\n",
            "Epoch 219: val_loss improved from 0.28904 to 0.28746, saving model to best_model.h5\n",
            "\n",
            "Epoch 220: val_loss improved from 0.28746 to 0.28588, saving model to best_model.h5\n",
            "\n",
            "Epoch 221: val_loss improved from 0.28588 to 0.28431, saving model to best_model.h5\n",
            "\n",
            "Epoch 222: val_loss improved from 0.28431 to 0.28275, saving model to best_model.h5\n",
            "\n",
            "Epoch 223: val_loss improved from 0.28275 to 0.28120, saving model to best_model.h5\n",
            "\n",
            "Epoch 224: val_loss improved from 0.28120 to 0.27966, saving model to best_model.h5\n",
            "\n",
            "Epoch 225: val_loss improved from 0.27966 to 0.27813, saving model to best_model.h5\n",
            "\n",
            "Epoch 226: val_loss improved from 0.27813 to 0.27660, saving model to best_model.h5\n",
            "\n",
            "Epoch 227: val_loss improved from 0.27660 to 0.27508, saving model to best_model.h5\n",
            "\n",
            "Epoch 228: val_loss improved from 0.27508 to 0.27357, saving model to best_model.h5\n",
            "\n",
            "Epoch 229: val_loss improved from 0.27357 to 0.27206, saving model to best_model.h5\n",
            "\n",
            "Epoch 230: val_loss improved from 0.27206 to 0.27056, saving model to best_model.h5\n",
            "\n",
            "Epoch 231: val_loss improved from 0.27056 to 0.26907, saving model to best_model.h5\n",
            "\n",
            "Epoch 232: val_loss improved from 0.26907 to 0.26758, saving model to best_model.h5\n",
            "\n",
            "Epoch 233: val_loss improved from 0.26758 to 0.26610, saving model to best_model.h5\n",
            "\n",
            "Epoch 234: val_loss improved from 0.26610 to 0.26462, saving model to best_model.h5\n",
            "\n",
            "Epoch 235: val_loss improved from 0.26462 to 0.26315, saving model to best_model.h5\n",
            "\n",
            "Epoch 236: val_loss improved from 0.26315 to 0.26167, saving model to best_model.h5\n",
            "\n",
            "Epoch 237: val_loss improved from 0.26167 to 0.26020, saving model to best_model.h5\n",
            "\n",
            "Epoch 238: val_loss improved from 0.26020 to 0.25873, saving model to best_model.h5\n",
            "\n",
            "Epoch 239: val_loss improved from 0.25873 to 0.25725, saving model to best_model.h5\n",
            "\n",
            "Epoch 240: val_loss improved from 0.25725 to 0.25578, saving model to best_model.h5\n",
            "\n",
            "Epoch 241: val_loss improved from 0.25578 to 0.25431, saving model to best_model.h5\n",
            "\n",
            "Epoch 242: val_loss improved from 0.25431 to 0.25284, saving model to best_model.h5\n",
            "\n",
            "Epoch 243: val_loss improved from 0.25284 to 0.25137, saving model to best_model.h5\n",
            "\n",
            "Epoch 244: val_loss improved from 0.25137 to 0.24992, saving model to best_model.h5\n",
            "\n",
            "Epoch 245: val_loss improved from 0.24992 to 0.24847, saving model to best_model.h5\n",
            "\n",
            "Epoch 246: val_loss improved from 0.24847 to 0.24702, saving model to best_model.h5\n",
            "\n",
            "Epoch 247: val_loss improved from 0.24702 to 0.24558, saving model to best_model.h5\n",
            "\n",
            "Epoch 248: val_loss improved from 0.24558 to 0.24413, saving model to best_model.h5\n",
            "\n",
            "Epoch 249: val_loss improved from 0.24413 to 0.24269, saving model to best_model.h5\n",
            "\n",
            "Epoch 250: val_loss improved from 0.24269 to 0.24124, saving model to best_model.h5\n",
            "\n",
            "Epoch 251: val_loss improved from 0.24124 to 0.23980, saving model to best_model.h5\n",
            "\n",
            "Epoch 252: val_loss improved from 0.23980 to 0.23835, saving model to best_model.h5\n",
            "\n",
            "Epoch 253: val_loss improved from 0.23835 to 0.23691, saving model to best_model.h5\n",
            "\n",
            "Epoch 254: val_loss improved from 0.23691 to 0.23547, saving model to best_model.h5\n",
            "\n",
            "Epoch 255: val_loss improved from 0.23547 to 0.23403, saving model to best_model.h5\n",
            "\n",
            "Epoch 256: val_loss improved from 0.23403 to 0.23259, saving model to best_model.h5\n",
            "\n",
            "Epoch 257: val_loss improved from 0.23259 to 0.23115, saving model to best_model.h5\n",
            "\n",
            "Epoch 258: val_loss improved from 0.23115 to 0.22971, saving model to best_model.h5\n",
            "\n",
            "Epoch 259: val_loss improved from 0.22971 to 0.22828, saving model to best_model.h5\n",
            "\n",
            "Epoch 260: val_loss improved from 0.22828 to 0.22685, saving model to best_model.h5\n",
            "\n",
            "Epoch 261: val_loss improved from 0.22685 to 0.22543, saving model to best_model.h5\n",
            "\n",
            "Epoch 262: val_loss improved from 0.22543 to 0.22402, saving model to best_model.h5\n",
            "\n",
            "Epoch 263: val_loss improved from 0.22402 to 0.22261, saving model to best_model.h5\n",
            "\n",
            "Epoch 264: val_loss improved from 0.22261 to 0.22122, saving model to best_model.h5\n",
            "\n",
            "Epoch 265: val_loss improved from 0.22122 to 0.21982, saving model to best_model.h5\n",
            "\n",
            "Epoch 266: val_loss improved from 0.21982 to 0.21844, saving model to best_model.h5\n",
            "\n",
            "Epoch 267: val_loss improved from 0.21844 to 0.21706, saving model to best_model.h5\n",
            "\n",
            "Epoch 268: val_loss improved from 0.21706 to 0.21569, saving model to best_model.h5\n",
            "\n",
            "Epoch 269: val_loss improved from 0.21569 to 0.21432, saving model to best_model.h5\n",
            "\n",
            "Epoch 270: val_loss improved from 0.21432 to 0.21296, saving model to best_model.h5\n",
            "\n",
            "Epoch 271: val_loss improved from 0.21296 to 0.21160, saving model to best_model.h5\n",
            "\n",
            "Epoch 272: val_loss improved from 0.21160 to 0.21025, saving model to best_model.h5\n",
            "\n",
            "Epoch 273: val_loss improved from 0.21025 to 0.20891, saving model to best_model.h5\n",
            "\n",
            "Epoch 274: val_loss improved from 0.20891 to 0.20757, saving model to best_model.h5\n",
            "\n",
            "Epoch 275: val_loss improved from 0.20757 to 0.20624, saving model to best_model.h5\n",
            "\n",
            "Epoch 276: val_loss improved from 0.20624 to 0.20491, saving model to best_model.h5\n",
            "\n",
            "Epoch 277: val_loss improved from 0.20491 to 0.20360, saving model to best_model.h5\n",
            "\n",
            "Epoch 278: val_loss improved from 0.20360 to 0.20229, saving model to best_model.h5\n",
            "\n",
            "Epoch 279: val_loss improved from 0.20229 to 0.20098, saving model to best_model.h5\n",
            "\n",
            "Epoch 280: val_loss improved from 0.20098 to 0.19969, saving model to best_model.h5\n",
            "\n",
            "Epoch 281: val_loss improved from 0.19969 to 0.19839, saving model to best_model.h5\n",
            "\n",
            "Epoch 282: val_loss improved from 0.19839 to 0.19711, saving model to best_model.h5\n",
            "\n",
            "Epoch 283: val_loss improved from 0.19711 to 0.19583, saving model to best_model.h5\n",
            "\n",
            "Epoch 284: val_loss improved from 0.19583 to 0.19456, saving model to best_model.h5\n",
            "\n",
            "Epoch 285: val_loss improved from 0.19456 to 0.19329, saving model to best_model.h5\n",
            "\n",
            "Epoch 286: val_loss improved from 0.19329 to 0.19204, saving model to best_model.h5\n",
            "\n",
            "Epoch 287: val_loss improved from 0.19204 to 0.19081, saving model to best_model.h5\n",
            "\n",
            "Epoch 288: val_loss improved from 0.19081 to 0.18958, saving model to best_model.h5\n",
            "\n",
            "Epoch 289: val_loss improved from 0.18958 to 0.18835, saving model to best_model.h5\n",
            "\n",
            "Epoch 290: val_loss improved from 0.18835 to 0.18714, saving model to best_model.h5\n",
            "\n",
            "Epoch 291: val_loss improved from 0.18714 to 0.18593, saving model to best_model.h5\n",
            "\n",
            "Epoch 292: val_loss improved from 0.18593 to 0.18472, saving model to best_model.h5\n",
            "\n",
            "Epoch 293: val_loss improved from 0.18472 to 0.18351, saving model to best_model.h5\n",
            "\n",
            "Epoch 294: val_loss improved from 0.18351 to 0.18231, saving model to best_model.h5\n",
            "\n",
            "Epoch 295: val_loss improved from 0.18231 to 0.18112, saving model to best_model.h5\n",
            "\n",
            "Epoch 296: val_loss improved from 0.18112 to 0.17996, saving model to best_model.h5\n",
            "\n",
            "Epoch 297: val_loss improved from 0.17996 to 0.17881, saving model to best_model.h5\n",
            "\n",
            "Epoch 298: val_loss improved from 0.17881 to 0.17768, saving model to best_model.h5\n",
            "\n",
            "Epoch 299: val_loss improved from 0.17768 to 0.17656, saving model to best_model.h5\n",
            "\n",
            "Epoch 300: val_loss improved from 0.17656 to 0.17546, saving model to best_model.h5\n",
            "\n",
            "Epoch 301: val_loss improved from 0.17546 to 0.17436, saving model to best_model.h5\n",
            "\n",
            "Epoch 302: val_loss improved from 0.17436 to 0.17327, saving model to best_model.h5\n",
            "\n",
            "Epoch 303: val_loss improved from 0.17327 to 0.17217, saving model to best_model.h5\n",
            "\n",
            "Epoch 304: val_loss improved from 0.17217 to 0.17109, saving model to best_model.h5\n",
            "\n",
            "Epoch 305: val_loss improved from 0.17109 to 0.17001, saving model to best_model.h5\n",
            "\n",
            "Epoch 306: val_loss improved from 0.17001 to 0.16892, saving model to best_model.h5\n",
            "\n",
            "Epoch 307: val_loss improved from 0.16892 to 0.16784, saving model to best_model.h5\n",
            "\n",
            "Epoch 308: val_loss improved from 0.16784 to 0.16675, saving model to best_model.h5\n",
            "\n",
            "Epoch 309: val_loss improved from 0.16675 to 0.16567, saving model to best_model.h5\n",
            "\n",
            "Epoch 310: val_loss improved from 0.16567 to 0.16458, saving model to best_model.h5\n",
            "\n",
            "Epoch 311: val_loss improved from 0.16458 to 0.16350, saving model to best_model.h5\n",
            "\n",
            "Epoch 312: val_loss improved from 0.16350 to 0.16241, saving model to best_model.h5\n",
            "\n",
            "Epoch 313: val_loss improved from 0.16241 to 0.16133, saving model to best_model.h5\n",
            "\n",
            "Epoch 314: val_loss improved from 0.16133 to 0.16026, saving model to best_model.h5\n",
            "\n",
            "Epoch 315: val_loss improved from 0.16026 to 0.15919, saving model to best_model.h5\n",
            "\n",
            "Epoch 316: val_loss improved from 0.15919 to 0.15813, saving model to best_model.h5\n",
            "\n",
            "Epoch 317: val_loss improved from 0.15813 to 0.15707, saving model to best_model.h5\n",
            "\n",
            "Epoch 318: val_loss improved from 0.15707 to 0.15602, saving model to best_model.h5\n",
            "\n",
            "Epoch 319: val_loss improved from 0.15602 to 0.15497, saving model to best_model.h5\n",
            "\n",
            "Epoch 320: val_loss improved from 0.15497 to 0.15394, saving model to best_model.h5\n",
            "\n",
            "Epoch 321: val_loss improved from 0.15394 to 0.15291, saving model to best_model.h5\n",
            "\n",
            "Epoch 322: val_loss improved from 0.15291 to 0.15189, saving model to best_model.h5\n",
            "\n",
            "Epoch 323: val_loss improved from 0.15189 to 0.15088, saving model to best_model.h5\n",
            "\n",
            "Epoch 324: val_loss improved from 0.15088 to 0.14988, saving model to best_model.h5\n",
            "\n",
            "Epoch 325: val_loss improved from 0.14988 to 0.14888, saving model to best_model.h5\n",
            "\n",
            "Epoch 326: val_loss improved from 0.14888 to 0.14790, saving model to best_model.h5\n",
            "\n",
            "Epoch 327: val_loss improved from 0.14790 to 0.14695, saving model to best_model.h5\n",
            "\n",
            "Epoch 328: val_loss improved from 0.14695 to 0.14604, saving model to best_model.h5\n",
            "\n",
            "Epoch 329: val_loss improved from 0.14604 to 0.14516, saving model to best_model.h5\n",
            "\n",
            "Epoch 330: val_loss improved from 0.14516 to 0.14430, saving model to best_model.h5\n",
            "\n",
            "Epoch 331: val_loss improved from 0.14430 to 0.14347, saving model to best_model.h5\n",
            "\n",
            "Epoch 332: val_loss improved from 0.14347 to 0.14267, saving model to best_model.h5\n",
            "\n",
            "Epoch 333: val_loss improved from 0.14267 to 0.14187, saving model to best_model.h5\n",
            "\n",
            "Epoch 334: val_loss improved from 0.14187 to 0.14110, saving model to best_model.h5\n",
            "\n",
            "Epoch 335: val_loss improved from 0.14110 to 0.14034, saving model to best_model.h5\n",
            "\n",
            "Epoch 336: val_loss improved from 0.14034 to 0.13958, saving model to best_model.h5\n",
            "\n",
            "Epoch 337: val_loss improved from 0.13958 to 0.13883, saving model to best_model.h5\n",
            "\n",
            "Epoch 338: val_loss improved from 0.13883 to 0.13809, saving model to best_model.h5\n",
            "\n",
            "Epoch 339: val_loss improved from 0.13809 to 0.13734, saving model to best_model.h5\n",
            "\n",
            "Epoch 340: val_loss improved from 0.13734 to 0.13660, saving model to best_model.h5\n",
            "\n",
            "Epoch 341: val_loss improved from 0.13660 to 0.13586, saving model to best_model.h5\n",
            "\n",
            "Epoch 342: val_loss improved from 0.13586 to 0.13511, saving model to best_model.h5\n",
            "\n",
            "Epoch 343: val_loss improved from 0.13511 to 0.13436, saving model to best_model.h5\n",
            "\n",
            "Epoch 344: val_loss improved from 0.13436 to 0.13361, saving model to best_model.h5\n",
            "\n",
            "Epoch 345: val_loss improved from 0.13361 to 0.13286, saving model to best_model.h5\n",
            "\n",
            "Epoch 346: val_loss improved from 0.13286 to 0.13211, saving model to best_model.h5\n",
            "\n",
            "Epoch 347: val_loss improved from 0.13211 to 0.13137, saving model to best_model.h5\n",
            "\n",
            "Epoch 348: val_loss improved from 0.13137 to 0.13064, saving model to best_model.h5\n",
            "\n",
            "Epoch 349: val_loss improved from 0.13064 to 0.12995, saving model to best_model.h5\n",
            "\n",
            "Epoch 350: val_loss improved from 0.12995 to 0.12925, saving model to best_model.h5\n",
            "\n",
            "Epoch 351: val_loss improved from 0.12925 to 0.12856, saving model to best_model.h5\n",
            "\n",
            "Epoch 352: val_loss improved from 0.12856 to 0.12787, saving model to best_model.h5\n",
            "\n",
            "Epoch 353: val_loss improved from 0.12787 to 0.12719, saving model to best_model.h5\n",
            "\n",
            "Epoch 354: val_loss improved from 0.12719 to 0.12652, saving model to best_model.h5\n",
            "\n",
            "Epoch 355: val_loss improved from 0.12652 to 0.12586, saving model to best_model.h5\n",
            "\n",
            "Epoch 356: val_loss improved from 0.12586 to 0.12520, saving model to best_model.h5\n",
            "\n",
            "Epoch 357: val_loss improved from 0.12520 to 0.12454, saving model to best_model.h5\n",
            "\n",
            "Epoch 358: val_loss improved from 0.12454 to 0.12390, saving model to best_model.h5\n",
            "\n",
            "Epoch 359: val_loss improved from 0.12390 to 0.12326, saving model to best_model.h5\n",
            "\n",
            "Epoch 360: val_loss improved from 0.12326 to 0.12262, saving model to best_model.h5\n",
            "\n",
            "Epoch 361: val_loss improved from 0.12262 to 0.12199, saving model to best_model.h5\n",
            "\n",
            "Epoch 362: val_loss improved from 0.12199 to 0.12137, saving model to best_model.h5\n",
            "\n",
            "Epoch 363: val_loss improved from 0.12137 to 0.12076, saving model to best_model.h5\n",
            "\n",
            "Epoch 364: val_loss improved from 0.12076 to 0.12016, saving model to best_model.h5\n",
            "\n",
            "Epoch 365: val_loss improved from 0.12016 to 0.11956, saving model to best_model.h5\n",
            "\n",
            "Epoch 366: val_loss improved from 0.11956 to 0.11896, saving model to best_model.h5\n",
            "\n",
            "Epoch 367: val_loss improved from 0.11896 to 0.11837, saving model to best_model.h5\n",
            "\n",
            "Epoch 368: val_loss improved from 0.11837 to 0.11778, saving model to best_model.h5\n",
            "\n",
            "Epoch 369: val_loss improved from 0.11778 to 0.11721, saving model to best_model.h5\n",
            "\n",
            "Epoch 370: val_loss improved from 0.11721 to 0.11664, saving model to best_model.h5\n",
            "\n",
            "Epoch 371: val_loss improved from 0.11664 to 0.11608, saving model to best_model.h5\n",
            "\n",
            "Epoch 372: val_loss improved from 0.11608 to 0.11557, saving model to best_model.h5\n",
            "\n",
            "Epoch 373: val_loss improved from 0.11557 to 0.11506, saving model to best_model.h5\n",
            "\n",
            "Epoch 374: val_loss improved from 0.11506 to 0.11456, saving model to best_model.h5\n",
            "\n",
            "Epoch 375: val_loss improved from 0.11456 to 0.11406, saving model to best_model.h5\n",
            "\n",
            "Epoch 376: val_loss improved from 0.11406 to 0.11357, saving model to best_model.h5\n",
            "\n",
            "Epoch 377: val_loss improved from 0.11357 to 0.11309, saving model to best_model.h5\n",
            "\n",
            "Epoch 378: val_loss improved from 0.11309 to 0.11262, saving model to best_model.h5\n",
            "\n",
            "Epoch 379: val_loss improved from 0.11262 to 0.11216, saving model to best_model.h5\n",
            "\n",
            "Epoch 380: val_loss improved from 0.11216 to 0.11170, saving model to best_model.h5\n",
            "\n",
            "Epoch 381: val_loss improved from 0.11170 to 0.11124, saving model to best_model.h5\n",
            "\n",
            "Epoch 382: val_loss improved from 0.11124 to 0.11078, saving model to best_model.h5\n",
            "\n",
            "Epoch 383: val_loss improved from 0.11078 to 0.11030, saving model to best_model.h5\n",
            "\n",
            "Epoch 384: val_loss improved from 0.11030 to 0.10982, saving model to best_model.h5\n",
            "\n",
            "Epoch 385: val_loss improved from 0.10982 to 0.10934, saving model to best_model.h5\n",
            "\n",
            "Epoch 386: val_loss improved from 0.10934 to 0.10886, saving model to best_model.h5\n",
            "\n",
            "Epoch 387: val_loss improved from 0.10886 to 0.10837, saving model to best_model.h5\n",
            "\n",
            "Epoch 388: val_loss improved from 0.10837 to 0.10788, saving model to best_model.h5\n",
            "\n",
            "Epoch 389: val_loss improved from 0.10788 to 0.10741, saving model to best_model.h5\n",
            "\n",
            "Epoch 390: val_loss improved from 0.10741 to 0.10693, saving model to best_model.h5\n",
            "\n",
            "Epoch 391: val_loss improved from 0.10693 to 0.10648, saving model to best_model.h5\n",
            "\n",
            "Epoch 392: val_loss improved from 0.10648 to 0.10603, saving model to best_model.h5\n",
            "\n",
            "Epoch 393: val_loss improved from 0.10603 to 0.10561, saving model to best_model.h5\n",
            "\n",
            "Epoch 394: val_loss improved from 0.10561 to 0.10520, saving model to best_model.h5\n",
            "\n",
            "Epoch 395: val_loss improved from 0.10520 to 0.10480, saving model to best_model.h5\n",
            "\n",
            "Epoch 396: val_loss improved from 0.10480 to 0.10442, saving model to best_model.h5\n",
            "\n",
            "Epoch 397: val_loss improved from 0.10442 to 0.10406, saving model to best_model.h5\n",
            "\n",
            "Epoch 398: val_loss improved from 0.10406 to 0.10372, saving model to best_model.h5\n",
            "\n",
            "Epoch 399: val_loss improved from 0.10372 to 0.10340, saving model to best_model.h5\n",
            "\n",
            "Epoch 400: val_loss improved from 0.10340 to 0.10309, saving model to best_model.h5\n",
            "\n",
            "Epoch 401: val_loss improved from 0.10309 to 0.10279, saving model to best_model.h5\n",
            "\n",
            "Epoch 402: val_loss improved from 0.10279 to 0.10248, saving model to best_model.h5\n",
            "\n",
            "Epoch 403: val_loss improved from 0.10248 to 0.10215, saving model to best_model.h5\n",
            "\n",
            "Epoch 404: val_loss improved from 0.10215 to 0.10180, saving model to best_model.h5\n",
            "\n",
            "Epoch 405: val_loss improved from 0.10180 to 0.10141, saving model to best_model.h5\n",
            "\n",
            "Epoch 406: val_loss improved from 0.10141 to 0.10100, saving model to best_model.h5\n",
            "\n",
            "Epoch 407: val_loss improved from 0.10100 to 0.10055, saving model to best_model.h5\n",
            "\n",
            "Epoch 408: val_loss improved from 0.10055 to 0.10011, saving model to best_model.h5\n",
            "\n",
            "Epoch 409: val_loss improved from 0.10011 to 0.09968, saving model to best_model.h5\n",
            "\n",
            "Epoch 410: val_loss improved from 0.09968 to 0.09926, saving model to best_model.h5\n",
            "\n",
            "Epoch 411: val_loss improved from 0.09926 to 0.09884, saving model to best_model.h5\n",
            "\n",
            "Epoch 412: val_loss improved from 0.09884 to 0.09844, saving model to best_model.h5\n",
            "\n",
            "Epoch 413: val_loss improved from 0.09844 to 0.09802, saving model to best_model.h5\n",
            "\n",
            "Epoch 414: val_loss improved from 0.09802 to 0.09760, saving model to best_model.h5\n",
            "\n",
            "Epoch 415: val_loss improved from 0.09760 to 0.09715, saving model to best_model.h5\n",
            "\n",
            "Epoch 416: val_loss improved from 0.09715 to 0.09669, saving model to best_model.h5\n",
            "\n",
            "Epoch 417: val_loss improved from 0.09669 to 0.09621, saving model to best_model.h5\n",
            "\n",
            "Epoch 418: val_loss improved from 0.09621 to 0.09572, saving model to best_model.h5\n",
            "\n",
            "Epoch 419: val_loss improved from 0.09572 to 0.09525, saving model to best_model.h5\n",
            "\n",
            "Epoch 420: val_loss improved from 0.09525 to 0.09481, saving model to best_model.h5\n",
            "\n",
            "Epoch 421: val_loss improved from 0.09481 to 0.09438, saving model to best_model.h5\n",
            "\n",
            "Epoch 422: val_loss improved from 0.09438 to 0.09397, saving model to best_model.h5\n",
            "\n",
            "Epoch 423: val_loss improved from 0.09397 to 0.09357, saving model to best_model.h5\n",
            "\n",
            "Epoch 424: val_loss improved from 0.09357 to 0.09315, saving model to best_model.h5\n",
            "\n",
            "Epoch 425: val_loss improved from 0.09315 to 0.09273, saving model to best_model.h5\n",
            "\n",
            "Epoch 426: val_loss improved from 0.09273 to 0.09229, saving model to best_model.h5\n",
            "\n",
            "Epoch 427: val_loss improved from 0.09229 to 0.09185, saving model to best_model.h5\n",
            "\n",
            "Epoch 428: val_loss improved from 0.09185 to 0.09143, saving model to best_model.h5\n",
            "\n",
            "Epoch 429: val_loss improved from 0.09143 to 0.09103, saving model to best_model.h5\n",
            "\n",
            "Epoch 430: val_loss improved from 0.09103 to 0.09064, saving model to best_model.h5\n",
            "\n",
            "Epoch 431: val_loss improved from 0.09064 to 0.09027, saving model to best_model.h5\n",
            "\n",
            "Epoch 432: val_loss improved from 0.09027 to 0.08991, saving model to best_model.h5\n",
            "\n",
            "Epoch 433: val_loss improved from 0.08991 to 0.08956, saving model to best_model.h5\n",
            "\n",
            "Epoch 434: val_loss improved from 0.08956 to 0.08921, saving model to best_model.h5\n",
            "\n",
            "Epoch 435: val_loss improved from 0.08921 to 0.08886, saving model to best_model.h5\n",
            "\n",
            "Epoch 436: val_loss improved from 0.08886 to 0.08851, saving model to best_model.h5\n",
            "\n",
            "Epoch 437: val_loss improved from 0.08851 to 0.08815, saving model to best_model.h5\n",
            "\n",
            "Epoch 438: val_loss improved from 0.08815 to 0.08781, saving model to best_model.h5\n",
            "\n",
            "Epoch 439: val_loss improved from 0.08781 to 0.08750, saving model to best_model.h5\n",
            "\n",
            "Epoch 440: val_loss improved from 0.08750 to 0.08721, saving model to best_model.h5\n",
            "\n",
            "Epoch 441: val_loss improved from 0.08721 to 0.08692, saving model to best_model.h5\n",
            "\n",
            "Epoch 442: val_loss improved from 0.08692 to 0.08665, saving model to best_model.h5\n",
            "\n",
            "Epoch 443: val_loss improved from 0.08665 to 0.08636, saving model to best_model.h5\n",
            "\n",
            "Epoch 444: val_loss improved from 0.08636 to 0.08607, saving model to best_model.h5\n",
            "\n",
            "Epoch 445: val_loss improved from 0.08607 to 0.08577, saving model to best_model.h5\n",
            "\n",
            "Epoch 446: val_loss improved from 0.08577 to 0.08545, saving model to best_model.h5\n",
            "\n",
            "Epoch 447: val_loss improved from 0.08545 to 0.08515, saving model to best_model.h5\n",
            "\n",
            "Epoch 448: val_loss improved from 0.08515 to 0.08485, saving model to best_model.h5\n",
            "\n",
            "Epoch 449: val_loss improved from 0.08485 to 0.08457, saving model to best_model.h5\n",
            "\n",
            "Epoch 450: val_loss improved from 0.08457 to 0.08429, saving model to best_model.h5\n",
            "\n",
            "Epoch 451: val_loss improved from 0.08429 to 0.08401, saving model to best_model.h5\n",
            "\n",
            "Epoch 452: val_loss improved from 0.08401 to 0.08374, saving model to best_model.h5\n",
            "\n",
            "Epoch 453: val_loss improved from 0.08374 to 0.08345, saving model to best_model.h5\n",
            "\n",
            "Epoch 454: val_loss improved from 0.08345 to 0.08315, saving model to best_model.h5\n",
            "\n",
            "Epoch 455: val_loss improved from 0.08315 to 0.08285, saving model to best_model.h5\n",
            "\n",
            "Epoch 456: val_loss improved from 0.08285 to 0.08253, saving model to best_model.h5\n",
            "\n",
            "Epoch 457: val_loss improved from 0.08253 to 0.08223, saving model to best_model.h5\n",
            "\n",
            "Epoch 458: val_loss improved from 0.08223 to 0.08194, saving model to best_model.h5\n",
            "\n",
            "Epoch 459: val_loss improved from 0.08194 to 0.08166, saving model to best_model.h5\n",
            "\n",
            "Epoch 460: val_loss improved from 0.08166 to 0.08139, saving model to best_model.h5\n",
            "\n",
            "Epoch 461: val_loss improved from 0.08139 to 0.08113, saving model to best_model.h5\n",
            "\n",
            "Epoch 462: val_loss improved from 0.08113 to 0.08088, saving model to best_model.h5\n",
            "\n",
            "Epoch 463: val_loss improved from 0.08088 to 0.08062, saving model to best_model.h5\n",
            "\n",
            "Epoch 464: val_loss improved from 0.08062 to 0.08037, saving model to best_model.h5\n",
            "\n",
            "Epoch 465: val_loss improved from 0.08037 to 0.08011, saving model to best_model.h5\n",
            "\n",
            "Epoch 466: val_loss improved from 0.08011 to 0.07984, saving model to best_model.h5\n",
            "\n",
            "Epoch 467: val_loss improved from 0.07984 to 0.07958, saving model to best_model.h5\n",
            "\n",
            "Epoch 468: val_loss improved from 0.07958 to 0.07933, saving model to best_model.h5\n",
            "\n",
            "Epoch 469: val_loss improved from 0.07933 to 0.07910, saving model to best_model.h5\n",
            "\n",
            "Epoch 470: val_loss improved from 0.07910 to 0.07887, saving model to best_model.h5\n",
            "\n",
            "Epoch 471: val_loss improved from 0.07887 to 0.07866, saving model to best_model.h5\n",
            "\n",
            "Epoch 472: val_loss improved from 0.07866 to 0.07844, saving model to best_model.h5\n",
            "\n",
            "Epoch 473: val_loss improved from 0.07844 to 0.07821, saving model to best_model.h5\n",
            "\n",
            "Epoch 474: val_loss improved from 0.07821 to 0.07798, saving model to best_model.h5\n",
            "\n",
            "Epoch 475: val_loss improved from 0.07798 to 0.07775, saving model to best_model.h5\n",
            "\n",
            "Epoch 476: val_loss improved from 0.07775 to 0.07752, saving model to best_model.h5\n",
            "\n",
            "Epoch 477: val_loss improved from 0.07752 to 0.07732, saving model to best_model.h5\n",
            "\n",
            "Epoch 478: val_loss improved from 0.07732 to 0.07712, saving model to best_model.h5\n",
            "\n",
            "Epoch 479: val_loss improved from 0.07712 to 0.07693, saving model to best_model.h5\n",
            "\n",
            "Epoch 480: val_loss improved from 0.07693 to 0.07675, saving model to best_model.h5\n",
            "\n",
            "Epoch 481: val_loss improved from 0.07675 to 0.07654, saving model to best_model.h5\n",
            "\n",
            "Epoch 482: val_loss improved from 0.07654 to 0.07632, saving model to best_model.h5\n",
            "\n",
            "Epoch 483: val_loss improved from 0.07632 to 0.07608, saving model to best_model.h5\n",
            "\n",
            "Epoch 484: val_loss improved from 0.07608 to 0.07584, saving model to best_model.h5\n",
            "\n",
            "Epoch 485: val_loss improved from 0.07584 to 0.07565, saving model to best_model.h5\n",
            "\n",
            "Epoch 486: val_loss improved from 0.07565 to 0.07554, saving model to best_model.h5\n",
            "\n",
            "Epoch 487: val_loss improved from 0.07554 to 0.07549, saving model to best_model.h5\n",
            "\n",
            "Epoch 488: val_loss improved from 0.07549 to 0.07547, saving model to best_model.h5\n",
            "\n",
            "Epoch 489: val_loss did not improve from 0.07547\n",
            "\n",
            "Epoch 490: val_loss did not improve from 0.07547\n",
            "\n",
            "Epoch 491: val_loss did not improve from 0.07547\n",
            "\n",
            "Epoch 492: val_loss did not improve from 0.07547\n",
            "\n",
            "Epoch 493: val_loss did not improve from 0.07547\n",
            "\n",
            "Epoch 494: val_loss did not improve from 0.07547\n",
            "\n",
            "Epoch 495: val_loss did not improve from 0.07547\n",
            "\n",
            "Epoch 496: val_loss did not improve from 0.07547\n",
            "\n",
            "Epoch 497: val_loss improved from 0.07547 to 0.07544, saving model to best_model.h5\n",
            "\n",
            "Epoch 498: val_loss improved from 0.07544 to 0.07531, saving model to best_model.h5\n",
            "\n",
            "Epoch 499: val_loss improved from 0.07531 to 0.07514, saving model to best_model.h5\n",
            "\n",
            "Epoch 500: val_loss improved from 0.07514 to 0.07494, saving model to best_model.h5\n",
            "\n",
            "Epoch 501: val_loss improved from 0.07494 to 0.07471, saving model to best_model.h5\n",
            "\n",
            "Epoch 502: val_loss improved from 0.07471 to 0.07444, saving model to best_model.h5\n",
            "\n",
            "Epoch 503: val_loss improved from 0.07444 to 0.07414, saving model to best_model.h5\n",
            "\n",
            "Epoch 504: val_loss improved from 0.07414 to 0.07382, saving model to best_model.h5\n",
            "\n",
            "Epoch 505: val_loss improved from 0.07382 to 0.07350, saving model to best_model.h5\n",
            "\n",
            "Epoch 506: val_loss improved from 0.07350 to 0.07317, saving model to best_model.h5\n",
            "\n",
            "Epoch 507: val_loss improved from 0.07317 to 0.07287, saving model to best_model.h5\n",
            "\n",
            "Epoch 508: val_loss improved from 0.07287 to 0.07259, saving model to best_model.h5\n",
            "\n",
            "Epoch 509: val_loss improved from 0.07259 to 0.07232, saving model to best_model.h5\n",
            "\n",
            "Epoch 510: val_loss improved from 0.07232 to 0.07207, saving model to best_model.h5\n",
            "\n",
            "Epoch 511: val_loss improved from 0.07207 to 0.07185, saving model to best_model.h5\n",
            "\n",
            "Epoch 512: val_loss improved from 0.07185 to 0.07164, saving model to best_model.h5\n",
            "\n",
            "Epoch 513: val_loss improved from 0.07164 to 0.07144, saving model to best_model.h5\n",
            "\n",
            "Epoch 514: val_loss improved from 0.07144 to 0.07125, saving model to best_model.h5\n",
            "\n",
            "Epoch 515: val_loss improved from 0.07125 to 0.07105, saving model to best_model.h5\n",
            "\n",
            "Epoch 516: val_loss improved from 0.07105 to 0.07087, saving model to best_model.h5\n",
            "\n",
            "Epoch 517: val_loss improved from 0.07087 to 0.07070, saving model to best_model.h5\n",
            "\n",
            "Epoch 518: val_loss improved from 0.07070 to 0.07053, saving model to best_model.h5\n",
            "\n",
            "Epoch 519: val_loss improved from 0.07053 to 0.07036, saving model to best_model.h5\n",
            "\n",
            "Epoch 520: val_loss improved from 0.07036 to 0.07017, saving model to best_model.h5\n",
            "\n",
            "Epoch 521: val_loss improved from 0.07017 to 0.06999, saving model to best_model.h5\n",
            "\n",
            "Epoch 522: val_loss improved from 0.06999 to 0.06982, saving model to best_model.h5\n",
            "\n",
            "Epoch 523: val_loss improved from 0.06982 to 0.06965, saving model to best_model.h5\n",
            "\n",
            "Epoch 524: val_loss improved from 0.06965 to 0.06950, saving model to best_model.h5\n",
            "\n",
            "Epoch 525: val_loss improved from 0.06950 to 0.06934, saving model to best_model.h5\n",
            "\n",
            "Epoch 526: val_loss improved from 0.06934 to 0.06918, saving model to best_model.h5\n",
            "\n",
            "Epoch 527: val_loss improved from 0.06918 to 0.06901, saving model to best_model.h5\n",
            "\n",
            "Epoch 528: val_loss improved from 0.06901 to 0.06885, saving model to best_model.h5\n",
            "\n",
            "Epoch 529: val_loss improved from 0.06885 to 0.06869, saving model to best_model.h5\n",
            "\n",
            "Epoch 530: val_loss improved from 0.06869 to 0.06852, saving model to best_model.h5\n",
            "\n",
            "Epoch 531: val_loss improved from 0.06852 to 0.06832, saving model to best_model.h5\n",
            "\n",
            "Epoch 532: val_loss improved from 0.06832 to 0.06812, saving model to best_model.h5\n",
            "\n",
            "Epoch 533: val_loss improved from 0.06812 to 0.06790, saving model to best_model.h5\n",
            "\n",
            "Epoch 534: val_loss improved from 0.06790 to 0.06769, saving model to best_model.h5\n",
            "\n",
            "Epoch 535: val_loss improved from 0.06769 to 0.06750, saving model to best_model.h5\n",
            "\n",
            "Epoch 536: val_loss improved from 0.06750 to 0.06731, saving model to best_model.h5\n",
            "\n",
            "Epoch 537: val_loss improved from 0.06731 to 0.06712, saving model to best_model.h5\n",
            "\n",
            "Epoch 538: val_loss improved from 0.06712 to 0.06693, saving model to best_model.h5\n",
            "\n",
            "Epoch 539: val_loss improved from 0.06693 to 0.06675, saving model to best_model.h5\n",
            "\n",
            "Epoch 540: val_loss improved from 0.06675 to 0.06658, saving model to best_model.h5\n",
            "\n",
            "Epoch 541: val_loss improved from 0.06658 to 0.06641, saving model to best_model.h5\n",
            "\n",
            "Epoch 542: val_loss improved from 0.06641 to 0.06622, saving model to best_model.h5\n",
            "\n",
            "Epoch 543: val_loss improved from 0.06622 to 0.06603, saving model to best_model.h5\n",
            "\n",
            "Epoch 544: val_loss improved from 0.06603 to 0.06583, saving model to best_model.h5\n",
            "\n",
            "Epoch 545: val_loss improved from 0.06583 to 0.06564, saving model to best_model.h5\n",
            "\n",
            "Epoch 546: val_loss improved from 0.06564 to 0.06546, saving model to best_model.h5\n",
            "\n",
            "Epoch 547: val_loss improved from 0.06546 to 0.06530, saving model to best_model.h5\n",
            "\n",
            "Epoch 548: val_loss improved from 0.06530 to 0.06513, saving model to best_model.h5\n",
            "\n",
            "Epoch 549: val_loss improved from 0.06513 to 0.06495, saving model to best_model.h5\n",
            "\n",
            "Epoch 550: val_loss improved from 0.06495 to 0.06476, saving model to best_model.h5\n",
            "\n",
            "Epoch 551: val_loss improved from 0.06476 to 0.06457, saving model to best_model.h5\n",
            "\n",
            "Epoch 552: val_loss improved from 0.06457 to 0.06437, saving model to best_model.h5\n",
            "\n",
            "Epoch 553: val_loss improved from 0.06437 to 0.06417, saving model to best_model.h5\n",
            "\n",
            "Epoch 554: val_loss improved from 0.06417 to 0.06394, saving model to best_model.h5\n",
            "\n",
            "Epoch 555: val_loss improved from 0.06394 to 0.06372, saving model to best_model.h5\n",
            "\n",
            "Epoch 556: val_loss improved from 0.06372 to 0.06350, saving model to best_model.h5\n",
            "\n",
            "Epoch 557: val_loss improved from 0.06350 to 0.06330, saving model to best_model.h5\n",
            "\n",
            "Epoch 558: val_loss improved from 0.06330 to 0.06311, saving model to best_model.h5\n",
            "\n",
            "Epoch 559: val_loss improved from 0.06311 to 0.06292, saving model to best_model.h5\n",
            "\n",
            "Epoch 560: val_loss improved from 0.06292 to 0.06273, saving model to best_model.h5\n",
            "\n",
            "Epoch 561: val_loss improved from 0.06273 to 0.06252, saving model to best_model.h5\n",
            "\n",
            "Epoch 562: val_loss improved from 0.06252 to 0.06233, saving model to best_model.h5\n",
            "\n",
            "Epoch 563: val_loss improved from 0.06233 to 0.06213, saving model to best_model.h5\n",
            "\n",
            "Epoch 564: val_loss improved from 0.06213 to 0.06194, saving model to best_model.h5\n",
            "\n",
            "Epoch 565: val_loss improved from 0.06194 to 0.06175, saving model to best_model.h5\n",
            "\n",
            "Epoch 566: val_loss improved from 0.06175 to 0.06156, saving model to best_model.h5\n",
            "\n",
            "Epoch 567: val_loss improved from 0.06156 to 0.06138, saving model to best_model.h5\n",
            "\n",
            "Epoch 568: val_loss improved from 0.06138 to 0.06120, saving model to best_model.h5\n",
            "\n",
            "Epoch 569: val_loss improved from 0.06120 to 0.06105, saving model to best_model.h5\n",
            "\n",
            "Epoch 570: val_loss improved from 0.06105 to 0.06090, saving model to best_model.h5\n",
            "\n",
            "Epoch 571: val_loss improved from 0.06090 to 0.06076, saving model to best_model.h5\n",
            "\n",
            "Epoch 572: val_loss improved from 0.06076 to 0.06061, saving model to best_model.h5\n",
            "\n",
            "Epoch 573: val_loss improved from 0.06061 to 0.06045, saving model to best_model.h5\n",
            "\n",
            "Epoch 574: val_loss improved from 0.06045 to 0.06028, saving model to best_model.h5\n",
            "\n",
            "Epoch 575: val_loss improved from 0.06028 to 0.06011, saving model to best_model.h5\n",
            "\n",
            "Epoch 576: val_loss improved from 0.06011 to 0.05993, saving model to best_model.h5\n",
            "\n",
            "Epoch 577: val_loss improved from 0.05993 to 0.05976, saving model to best_model.h5\n",
            "\n",
            "Epoch 578: val_loss improved from 0.05976 to 0.05958, saving model to best_model.h5\n",
            "\n",
            "Epoch 579: val_loss improved from 0.05958 to 0.05943, saving model to best_model.h5\n",
            "\n",
            "Epoch 580: val_loss improved from 0.05943 to 0.05929, saving model to best_model.h5\n",
            "\n",
            "Epoch 581: val_loss improved from 0.05929 to 0.05916, saving model to best_model.h5\n",
            "\n",
            "Epoch 582: val_loss improved from 0.05916 to 0.05901, saving model to best_model.h5\n",
            "\n",
            "Epoch 583: val_loss improved from 0.05901 to 0.05886, saving model to best_model.h5\n",
            "\n",
            "Epoch 584: val_loss improved from 0.05886 to 0.05869, saving model to best_model.h5\n",
            "\n",
            "Epoch 585: val_loss improved from 0.05869 to 0.05852, saving model to best_model.h5\n",
            "\n",
            "Epoch 586: val_loss improved from 0.05852 to 0.05833, saving model to best_model.h5\n",
            "\n",
            "Epoch 587: val_loss improved from 0.05833 to 0.05816, saving model to best_model.h5\n",
            "\n",
            "Epoch 588: val_loss improved from 0.05816 to 0.05800, saving model to best_model.h5\n",
            "\n",
            "Epoch 589: val_loss improved from 0.05800 to 0.05783, saving model to best_model.h5\n",
            "\n",
            "Epoch 590: val_loss improved from 0.05783 to 0.05767, saving model to best_model.h5\n",
            "\n",
            "Epoch 591: val_loss improved from 0.05767 to 0.05751, saving model to best_model.h5\n",
            "\n",
            "Epoch 592: val_loss improved from 0.05751 to 0.05736, saving model to best_model.h5\n",
            "\n",
            "Epoch 593: val_loss improved from 0.05736 to 0.05722, saving model to best_model.h5\n",
            "\n",
            "Epoch 594: val_loss improved from 0.05722 to 0.05707, saving model to best_model.h5\n",
            "\n",
            "Epoch 595: val_loss improved from 0.05707 to 0.05691, saving model to best_model.h5\n",
            "\n",
            "Epoch 596: val_loss improved from 0.05691 to 0.05675, saving model to best_model.h5\n",
            "\n",
            "Epoch 597: val_loss improved from 0.05675 to 0.05657, saving model to best_model.h5\n",
            "\n",
            "Epoch 598: val_loss improved from 0.05657 to 0.05640, saving model to best_model.h5\n",
            "\n",
            "Epoch 599: val_loss improved from 0.05640 to 0.05624, saving model to best_model.h5\n",
            "\n",
            "Epoch 600: val_loss improved from 0.05624 to 0.05609, saving model to best_model.h5\n",
            "\n",
            "Epoch 601: val_loss improved from 0.05609 to 0.05594, saving model to best_model.h5\n",
            "\n",
            "Epoch 602: val_loss improved from 0.05594 to 0.05580, saving model to best_model.h5\n",
            "\n",
            "Epoch 603: val_loss improved from 0.05580 to 0.05566, saving model to best_model.h5\n",
            "\n",
            "Epoch 604: val_loss improved from 0.05566 to 0.05552, saving model to best_model.h5\n",
            "\n",
            "Epoch 605: val_loss improved from 0.05552 to 0.05539, saving model to best_model.h5\n",
            "\n",
            "Epoch 606: val_loss improved from 0.05539 to 0.05527, saving model to best_model.h5\n",
            "\n",
            "Epoch 607: val_loss improved from 0.05527 to 0.05515, saving model to best_model.h5\n",
            "\n",
            "Epoch 608: val_loss improved from 0.05515 to 0.05502, saving model to best_model.h5\n",
            "\n",
            "Epoch 609: val_loss improved from 0.05502 to 0.05488, saving model to best_model.h5\n",
            "\n",
            "Epoch 610: val_loss improved from 0.05488 to 0.05475, saving model to best_model.h5\n",
            "\n",
            "Epoch 611: val_loss improved from 0.05475 to 0.05463, saving model to best_model.h5\n",
            "\n",
            "Epoch 612: val_loss improved from 0.05463 to 0.05452, saving model to best_model.h5\n",
            "\n",
            "Epoch 613: val_loss improved from 0.05452 to 0.05440, saving model to best_model.h5\n",
            "\n",
            "Epoch 614: val_loss improved from 0.05440 to 0.05428, saving model to best_model.h5\n",
            "\n",
            "Epoch 615: val_loss improved from 0.05428 to 0.05415, saving model to best_model.h5\n",
            "\n",
            "Epoch 616: val_loss improved from 0.05415 to 0.05401, saving model to best_model.h5\n",
            "\n",
            "Epoch 617: val_loss improved from 0.05401 to 0.05387, saving model to best_model.h5\n",
            "\n",
            "Epoch 618: val_loss improved from 0.05387 to 0.05375, saving model to best_model.h5\n",
            "\n",
            "Epoch 619: val_loss improved from 0.05375 to 0.05363, saving model to best_model.h5\n",
            "\n",
            "Epoch 620: val_loss improved from 0.05363 to 0.05351, saving model to best_model.h5\n",
            "\n",
            "Epoch 621: val_loss improved from 0.05351 to 0.05339, saving model to best_model.h5\n",
            "\n",
            "Epoch 622: val_loss improved from 0.05339 to 0.05326, saving model to best_model.h5\n",
            "\n",
            "Epoch 623: val_loss improved from 0.05326 to 0.05313, saving model to best_model.h5\n",
            "\n",
            "Epoch 624: val_loss improved from 0.05313 to 0.05301, saving model to best_model.h5\n",
            "\n",
            "Epoch 625: val_loss improved from 0.05301 to 0.05290, saving model to best_model.h5\n",
            "\n",
            "Epoch 626: val_loss improved from 0.05290 to 0.05279, saving model to best_model.h5\n",
            "\n",
            "Epoch 627: val_loss improved from 0.05279 to 0.05267, saving model to best_model.h5\n",
            "\n",
            "Epoch 628: val_loss improved from 0.05267 to 0.05255, saving model to best_model.h5\n",
            "\n",
            "Epoch 629: val_loss improved from 0.05255 to 0.05242, saving model to best_model.h5\n",
            "\n",
            "Epoch 630: val_loss improved from 0.05242 to 0.05229, saving model to best_model.h5\n",
            "\n",
            "Epoch 631: val_loss improved from 0.05229 to 0.05218, saving model to best_model.h5\n",
            "\n",
            "Epoch 632: val_loss improved from 0.05218 to 0.05208, saving model to best_model.h5\n",
            "\n",
            "Epoch 633: val_loss improved from 0.05208 to 0.05198, saving model to best_model.h5\n",
            "\n",
            "Epoch 634: val_loss improved from 0.05198 to 0.05188, saving model to best_model.h5\n",
            "\n",
            "Epoch 635: val_loss improved from 0.05188 to 0.05177, saving model to best_model.h5\n",
            "\n",
            "Epoch 636: val_loss improved from 0.05177 to 0.05166, saving model to best_model.h5\n",
            "\n",
            "Epoch 637: val_loss improved from 0.05166 to 0.05154, saving model to best_model.h5\n",
            "\n",
            "Epoch 638: val_loss improved from 0.05154 to 0.05142, saving model to best_model.h5\n",
            "\n",
            "Epoch 639: val_loss improved from 0.05142 to 0.05130, saving model to best_model.h5\n",
            "\n",
            "Epoch 640: val_loss improved from 0.05130 to 0.05118, saving model to best_model.h5\n",
            "\n",
            "Epoch 641: val_loss improved from 0.05118 to 0.05105, saving model to best_model.h5\n",
            "\n",
            "Epoch 642: val_loss improved from 0.05105 to 0.05095, saving model to best_model.h5\n",
            "\n",
            "Epoch 643: val_loss improved from 0.05095 to 0.05087, saving model to best_model.h5\n",
            "\n",
            "Epoch 644: val_loss improved from 0.05087 to 0.05080, saving model to best_model.h5\n",
            "\n",
            "Epoch 645: val_loss improved from 0.05080 to 0.05073, saving model to best_model.h5\n",
            "\n",
            "Epoch 646: val_loss improved from 0.05073 to 0.05067, saving model to best_model.h5\n",
            "\n",
            "Epoch 647: val_loss improved from 0.05067 to 0.05060, saving model to best_model.h5\n",
            "\n",
            "Epoch 648: val_loss improved from 0.05060 to 0.05053, saving model to best_model.h5\n",
            "\n",
            "Epoch 649: val_loss improved from 0.05053 to 0.05046, saving model to best_model.h5\n",
            "\n",
            "Epoch 650: val_loss improved from 0.05046 to 0.05039, saving model to best_model.h5\n",
            "\n",
            "Epoch 651: val_loss improved from 0.05039 to 0.05031, saving model to best_model.h5\n",
            "\n",
            "Epoch 652: val_loss improved from 0.05031 to 0.05024, saving model to best_model.h5\n",
            "\n",
            "Epoch 653: val_loss improved from 0.05024 to 0.05015, saving model to best_model.h5\n",
            "\n",
            "Epoch 654: val_loss improved from 0.05015 to 0.05007, saving model to best_model.h5\n",
            "\n",
            "Epoch 655: val_loss improved from 0.05007 to 0.04998, saving model to best_model.h5\n",
            "\n",
            "Epoch 656: val_loss improved from 0.04998 to 0.04989, saving model to best_model.h5\n",
            "\n",
            "Epoch 657: val_loss improved from 0.04989 to 0.04980, saving model to best_model.h5\n",
            "\n",
            "Epoch 658: val_loss improved from 0.04980 to 0.04972, saving model to best_model.h5\n",
            "\n",
            "Epoch 659: val_loss improved from 0.04972 to 0.04964, saving model to best_model.h5\n",
            "\n",
            "Epoch 660: val_loss improved from 0.04964 to 0.04958, saving model to best_model.h5\n",
            "\n",
            "Epoch 661: val_loss improved from 0.04958 to 0.04951, saving model to best_model.h5\n",
            "\n",
            "Epoch 662: val_loss improved from 0.04951 to 0.04943, saving model to best_model.h5\n",
            "\n",
            "Epoch 663: val_loss improved from 0.04943 to 0.04936, saving model to best_model.h5\n",
            "\n",
            "Epoch 664: val_loss improved from 0.04936 to 0.04928, saving model to best_model.h5\n",
            "\n",
            "Epoch 665: val_loss improved from 0.04928 to 0.04920, saving model to best_model.h5\n",
            "\n",
            "Epoch 666: val_loss improved from 0.04920 to 0.04911, saving model to best_model.h5\n",
            "\n",
            "Epoch 667: val_loss improved from 0.04911 to 0.04903, saving model to best_model.h5\n",
            "\n",
            "Epoch 668: val_loss improved from 0.04903 to 0.04894, saving model to best_model.h5\n",
            "\n",
            "Epoch 669: val_loss improved from 0.04894 to 0.04885, saving model to best_model.h5\n",
            "\n",
            "Epoch 670: val_loss improved from 0.04885 to 0.04876, saving model to best_model.h5\n",
            "\n",
            "Epoch 671: val_loss improved from 0.04876 to 0.04867, saving model to best_model.h5\n",
            "\n",
            "Epoch 672: val_loss improved from 0.04867 to 0.04863, saving model to best_model.h5\n",
            "\n",
            "Epoch 673: val_loss improved from 0.04863 to 0.04862, saving model to best_model.h5\n",
            "\n",
            "Epoch 674: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 675: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 676: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 677: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 678: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 679: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 680: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 681: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 682: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 683: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 684: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 685: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 686: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 687: val_loss did not improve from 0.04862\n",
            "\n",
            "Epoch 688: val_loss improved from 0.04862 to 0.04861, saving model to best_model.h5\n",
            "\n",
            "Epoch 689: val_loss improved from 0.04861 to 0.04852, saving model to best_model.h5\n",
            "\n",
            "Epoch 690: val_loss improved from 0.04852 to 0.04842, saving model to best_model.h5\n",
            "\n",
            "Epoch 691: val_loss improved from 0.04842 to 0.04833, saving model to best_model.h5\n",
            "\n",
            "Epoch 692: val_loss improved from 0.04833 to 0.04823, saving model to best_model.h5\n",
            "\n",
            "Epoch 693: val_loss improved from 0.04823 to 0.04812, saving model to best_model.h5\n",
            "\n",
            "Epoch 694: val_loss improved from 0.04812 to 0.04803, saving model to best_model.h5\n",
            "\n",
            "Epoch 695: val_loss improved from 0.04803 to 0.04794, saving model to best_model.h5\n",
            "\n",
            "Epoch 696: val_loss improved from 0.04794 to 0.04786, saving model to best_model.h5\n",
            "\n",
            "Epoch 697: val_loss improved from 0.04786 to 0.04780, saving model to best_model.h5\n",
            "\n",
            "Epoch 698: val_loss improved from 0.04780 to 0.04774, saving model to best_model.h5\n",
            "\n",
            "Epoch 699: val_loss improved from 0.04774 to 0.04767, saving model to best_model.h5\n",
            "\n",
            "Epoch 700: val_loss improved from 0.04767 to 0.04760, saving model to best_model.h5\n",
            "\n",
            "Epoch 701: val_loss improved from 0.04760 to 0.04753, saving model to best_model.h5\n",
            "\n",
            "Epoch 702: val_loss improved from 0.04753 to 0.04746, saving model to best_model.h5\n",
            "\n",
            "Epoch 703: val_loss improved from 0.04746 to 0.04739, saving model to best_model.h5\n",
            "\n",
            "Epoch 704: val_loss improved from 0.04739 to 0.04731, saving model to best_model.h5\n",
            "\n",
            "Epoch 705: val_loss improved from 0.04731 to 0.04723, saving model to best_model.h5\n",
            "\n",
            "Epoch 706: val_loss improved from 0.04723 to 0.04714, saving model to best_model.h5\n",
            "\n",
            "Epoch 707: val_loss improved from 0.04714 to 0.04705, saving model to best_model.h5\n",
            "\n",
            "Epoch 708: val_loss improved from 0.04705 to 0.04697, saving model to best_model.h5\n",
            "\n",
            "Epoch 709: val_loss improved from 0.04697 to 0.04689, saving model to best_model.h5\n",
            "\n",
            "Epoch 710: val_loss improved from 0.04689 to 0.04681, saving model to best_model.h5\n",
            "\n",
            "Epoch 711: val_loss improved from 0.04681 to 0.04672, saving model to best_model.h5\n",
            "\n",
            "Epoch 712: val_loss improved from 0.04672 to 0.04663, saving model to best_model.h5\n",
            "\n",
            "Epoch 713: val_loss improved from 0.04663 to 0.04652, saving model to best_model.h5\n",
            "\n",
            "Epoch 714: val_loss improved from 0.04652 to 0.04643, saving model to best_model.h5\n",
            "\n",
            "Epoch 715: val_loss improved from 0.04643 to 0.04632, saving model to best_model.h5\n",
            "\n",
            "Epoch 716: val_loss improved from 0.04632 to 0.04622, saving model to best_model.h5\n",
            "\n",
            "Epoch 717: val_loss improved from 0.04622 to 0.04610, saving model to best_model.h5\n",
            "\n",
            "Epoch 718: val_loss improved from 0.04610 to 0.04600, saving model to best_model.h5\n",
            "\n",
            "Epoch 719: val_loss improved from 0.04600 to 0.04588, saving model to best_model.h5\n",
            "\n",
            "Epoch 720: val_loss improved from 0.04588 to 0.04577, saving model to best_model.h5\n",
            "\n",
            "Epoch 721: val_loss improved from 0.04577 to 0.04565, saving model to best_model.h5\n",
            "\n",
            "Epoch 722: val_loss improved from 0.04565 to 0.04554, saving model to best_model.h5\n",
            "\n",
            "Epoch 723: val_loss improved from 0.04554 to 0.04543, saving model to best_model.h5\n",
            "\n",
            "Epoch 724: val_loss improved from 0.04543 to 0.04532, saving model to best_model.h5\n",
            "\n",
            "Epoch 725: val_loss improved from 0.04532 to 0.04521, saving model to best_model.h5\n",
            "\n",
            "Epoch 726: val_loss improved from 0.04521 to 0.04510, saving model to best_model.h5\n",
            "\n",
            "Epoch 727: val_loss improved from 0.04510 to 0.04499, saving model to best_model.h5\n",
            "\n",
            "Epoch 728: val_loss improved from 0.04499 to 0.04489, saving model to best_model.h5\n",
            "\n",
            "Epoch 729: val_loss improved from 0.04489 to 0.04480, saving model to best_model.h5\n",
            "\n",
            "Epoch 730: val_loss improved from 0.04480 to 0.04472, saving model to best_model.h5\n",
            "\n",
            "Epoch 731: val_loss improved from 0.04472 to 0.04465, saving model to best_model.h5\n",
            "\n",
            "Epoch 732: val_loss improved from 0.04465 to 0.04459, saving model to best_model.h5\n",
            "\n",
            "Epoch 733: val_loss improved from 0.04459 to 0.04452, saving model to best_model.h5\n",
            "\n",
            "Epoch 734: val_loss improved from 0.04452 to 0.04445, saving model to best_model.h5\n",
            "\n",
            "Epoch 735: val_loss improved from 0.04445 to 0.04439, saving model to best_model.h5\n",
            "\n",
            "Epoch 736: val_loss improved from 0.04439 to 0.04432, saving model to best_model.h5\n",
            "\n",
            "Epoch 737: val_loss improved from 0.04432 to 0.04426, saving model to best_model.h5\n",
            "\n",
            "Epoch 738: val_loss improved from 0.04426 to 0.04420, saving model to best_model.h5\n",
            "\n",
            "Epoch 739: val_loss improved from 0.04420 to 0.04413, saving model to best_model.h5\n",
            "\n",
            "Epoch 740: val_loss improved from 0.04413 to 0.04407, saving model to best_model.h5\n",
            "\n",
            "Epoch 741: val_loss improved from 0.04407 to 0.04400, saving model to best_model.h5\n",
            "\n",
            "Epoch 742: val_loss improved from 0.04400 to 0.04394, saving model to best_model.h5\n",
            "\n",
            "Epoch 743: val_loss improved from 0.04394 to 0.04388, saving model to best_model.h5\n",
            "\n",
            "Epoch 744: val_loss improved from 0.04388 to 0.04382, saving model to best_model.h5\n",
            "\n",
            "Epoch 745: val_loss improved from 0.04382 to 0.04375, saving model to best_model.h5\n",
            "\n",
            "Epoch 746: val_loss improved from 0.04375 to 0.04367, saving model to best_model.h5\n",
            "\n",
            "Epoch 747: val_loss improved from 0.04367 to 0.04360, saving model to best_model.h5\n",
            "\n",
            "Epoch 748: val_loss improved from 0.04360 to 0.04352, saving model to best_model.h5\n",
            "\n",
            "Epoch 749: val_loss improved from 0.04352 to 0.04345, saving model to best_model.h5\n",
            "\n",
            "Epoch 750: val_loss improved from 0.04345 to 0.04337, saving model to best_model.h5\n",
            "\n",
            "Epoch 751: val_loss improved from 0.04337 to 0.04330, saving model to best_model.h5\n",
            "\n",
            "Epoch 752: val_loss improved from 0.04330 to 0.04323, saving model to best_model.h5\n",
            "\n",
            "Epoch 753: val_loss improved from 0.04323 to 0.04315, saving model to best_model.h5\n",
            "\n",
            "Epoch 754: val_loss improved from 0.04315 to 0.04308, saving model to best_model.h5\n",
            "\n",
            "Epoch 755: val_loss improved from 0.04308 to 0.04300, saving model to best_model.h5\n",
            "\n",
            "Epoch 756: val_loss improved from 0.04300 to 0.04292, saving model to best_model.h5\n",
            "\n",
            "Epoch 757: val_loss improved from 0.04292 to 0.04285, saving model to best_model.h5\n",
            "\n",
            "Epoch 758: val_loss improved from 0.04285 to 0.04280, saving model to best_model.h5\n",
            "\n",
            "Epoch 759: val_loss improved from 0.04280 to 0.04274, saving model to best_model.h5\n",
            "\n",
            "Epoch 760: val_loss improved from 0.04274 to 0.04268, saving model to best_model.h5\n",
            "\n",
            "Epoch 761: val_loss improved from 0.04268 to 0.04262, saving model to best_model.h5\n",
            "\n",
            "Epoch 762: val_loss improved from 0.04262 to 0.04253, saving model to best_model.h5\n",
            "\n",
            "Epoch 763: val_loss improved from 0.04253 to 0.04242, saving model to best_model.h5\n",
            "\n",
            "Epoch 764: val_loss improved from 0.04242 to 0.04228, saving model to best_model.h5\n",
            "\n",
            "Epoch 765: val_loss improved from 0.04228 to 0.04214, saving model to best_model.h5\n",
            "\n",
            "Epoch 766: val_loss improved from 0.04214 to 0.04200, saving model to best_model.h5\n",
            "\n",
            "Epoch 767: val_loss improved from 0.04200 to 0.04188, saving model to best_model.h5\n",
            "\n",
            "Epoch 768: val_loss improved from 0.04188 to 0.04179, saving model to best_model.h5\n",
            "\n",
            "Epoch 769: val_loss improved from 0.04179 to 0.04173, saving model to best_model.h5\n",
            "\n",
            "Epoch 770: val_loss improved from 0.04173 to 0.04167, saving model to best_model.h5\n",
            "\n",
            "Epoch 771: val_loss improved from 0.04167 to 0.04163, saving model to best_model.h5\n",
            "\n",
            "Epoch 772: val_loss improved from 0.04163 to 0.04160, saving model to best_model.h5\n",
            "\n",
            "Epoch 773: val_loss improved from 0.04160 to 0.04157, saving model to best_model.h5\n",
            "\n",
            "Epoch 774: val_loss improved from 0.04157 to 0.04151, saving model to best_model.h5\n",
            "\n",
            "Epoch 775: val_loss improved from 0.04151 to 0.04144, saving model to best_model.h5\n",
            "\n",
            "Epoch 776: val_loss improved from 0.04144 to 0.04134, saving model to best_model.h5\n",
            "\n",
            "Epoch 777: val_loss improved from 0.04134 to 0.04125, saving model to best_model.h5\n",
            "\n",
            "Epoch 778: val_loss improved from 0.04125 to 0.04117, saving model to best_model.h5\n",
            "\n",
            "Epoch 779: val_loss improved from 0.04117 to 0.04109, saving model to best_model.h5\n",
            "\n",
            "Epoch 780: val_loss improved from 0.04109 to 0.04101, saving model to best_model.h5\n",
            "\n",
            "Epoch 781: val_loss improved from 0.04101 to 0.04095, saving model to best_model.h5\n",
            "\n",
            "Epoch 782: val_loss improved from 0.04095 to 0.04090, saving model to best_model.h5\n",
            "\n",
            "Epoch 783: val_loss improved from 0.04090 to 0.04086, saving model to best_model.h5\n",
            "\n",
            "Epoch 784: val_loss improved from 0.04086 to 0.04082, saving model to best_model.h5\n",
            "\n",
            "Epoch 785: val_loss improved from 0.04082 to 0.04077, saving model to best_model.h5\n",
            "\n",
            "Epoch 786: val_loss improved from 0.04077 to 0.04072, saving model to best_model.h5\n",
            "\n",
            "Epoch 787: val_loss improved from 0.04072 to 0.04063, saving model to best_model.h5\n",
            "\n",
            "Epoch 788: val_loss improved from 0.04063 to 0.04052, saving model to best_model.h5\n",
            "\n",
            "Epoch 789: val_loss improved from 0.04052 to 0.04041, saving model to best_model.h5\n",
            "\n",
            "Epoch 790: val_loss improved from 0.04041 to 0.04031, saving model to best_model.h5\n",
            "\n",
            "Epoch 791: val_loss improved from 0.04031 to 0.04023, saving model to best_model.h5\n",
            "\n",
            "Epoch 792: val_loss improved from 0.04023 to 0.04016, saving model to best_model.h5\n",
            "\n",
            "Epoch 793: val_loss improved from 0.04016 to 0.04010, saving model to best_model.h5\n",
            "\n",
            "Epoch 794: val_loss improved from 0.04010 to 0.04005, saving model to best_model.h5\n",
            "\n",
            "Epoch 795: val_loss improved from 0.04005 to 0.04000, saving model to best_model.h5\n",
            "\n",
            "Epoch 796: val_loss improved from 0.04000 to 0.03995, saving model to best_model.h5\n",
            "\n",
            "Epoch 797: val_loss improved from 0.03995 to 0.03989, saving model to best_model.h5\n",
            "\n",
            "Epoch 798: val_loss improved from 0.03989 to 0.03982, saving model to best_model.h5\n",
            "\n",
            "Epoch 799: val_loss improved from 0.03982 to 0.03971, saving model to best_model.h5\n",
            "\n",
            "Epoch 800: val_loss improved from 0.03971 to 0.03962, saving model to best_model.h5\n",
            "\n",
            "Epoch 801: val_loss improved from 0.03962 to 0.03953, saving model to best_model.h5\n",
            "\n",
            "Epoch 802: val_loss improved from 0.03953 to 0.03945, saving model to best_model.h5\n",
            "\n",
            "Epoch 803: val_loss improved from 0.03945 to 0.03938, saving model to best_model.h5\n",
            "\n",
            "Epoch 804: val_loss improved from 0.03938 to 0.03933, saving model to best_model.h5\n",
            "\n",
            "Epoch 805: val_loss improved from 0.03933 to 0.03929, saving model to best_model.h5\n",
            "\n",
            "Epoch 806: val_loss improved from 0.03929 to 0.03926, saving model to best_model.h5\n",
            "\n",
            "Epoch 807: val_loss improved from 0.03926 to 0.03923, saving model to best_model.h5\n",
            "\n",
            "Epoch 808: val_loss improved from 0.03923 to 0.03918, saving model to best_model.h5\n",
            "\n",
            "Epoch 809: val_loss improved from 0.03918 to 0.03913, saving model to best_model.h5\n",
            "\n",
            "Epoch 810: val_loss improved from 0.03913 to 0.03907, saving model to best_model.h5\n",
            "\n",
            "Epoch 811: val_loss improved from 0.03907 to 0.03902, saving model to best_model.h5\n",
            "\n",
            "Epoch 812: val_loss improved from 0.03902 to 0.03897, saving model to best_model.h5\n",
            "\n",
            "Epoch 813: val_loss improved from 0.03897 to 0.03892, saving model to best_model.h5\n",
            "\n",
            "Epoch 814: val_loss improved from 0.03892 to 0.03888, saving model to best_model.h5\n",
            "\n",
            "Epoch 815: val_loss improved from 0.03888 to 0.03884, saving model to best_model.h5\n",
            "\n",
            "Epoch 816: val_loss improved from 0.03884 to 0.03880, saving model to best_model.h5\n",
            "\n",
            "Epoch 817: val_loss improved from 0.03880 to 0.03876, saving model to best_model.h5\n",
            "\n",
            "Epoch 818: val_loss improved from 0.03876 to 0.03871, saving model to best_model.h5\n",
            "\n",
            "Epoch 819: val_loss improved from 0.03871 to 0.03866, saving model to best_model.h5\n",
            "\n",
            "Epoch 820: val_loss improved from 0.03866 to 0.03862, saving model to best_model.h5\n",
            "\n",
            "Epoch 821: val_loss improved from 0.03862 to 0.03858, saving model to best_model.h5\n",
            "\n",
            "Epoch 822: val_loss improved from 0.03858 to 0.03853, saving model to best_model.h5\n",
            "\n",
            "Epoch 823: val_loss improved from 0.03853 to 0.03848, saving model to best_model.h5\n",
            "\n",
            "Epoch 824: val_loss improved from 0.03848 to 0.03842, saving model to best_model.h5\n",
            "\n",
            "Epoch 825: val_loss improved from 0.03842 to 0.03836, saving model to best_model.h5\n",
            "\n",
            "Epoch 826: val_loss improved from 0.03836 to 0.03830, saving model to best_model.h5\n",
            "\n",
            "Epoch 827: val_loss improved from 0.03830 to 0.03824, saving model to best_model.h5\n",
            "\n",
            "Epoch 828: val_loss improved from 0.03824 to 0.03818, saving model to best_model.h5\n",
            "\n",
            "Epoch 829: val_loss improved from 0.03818 to 0.03812, saving model to best_model.h5\n",
            "\n",
            "Epoch 830: val_loss improved from 0.03812 to 0.03807, saving model to best_model.h5\n",
            "\n",
            "Epoch 831: val_loss improved from 0.03807 to 0.03801, saving model to best_model.h5\n",
            "\n",
            "Epoch 832: val_loss improved from 0.03801 to 0.03795, saving model to best_model.h5\n",
            "\n",
            "Epoch 833: val_loss improved from 0.03795 to 0.03789, saving model to best_model.h5\n",
            "\n",
            "Epoch 834: val_loss improved from 0.03789 to 0.03783, saving model to best_model.h5\n",
            "\n",
            "Epoch 835: val_loss improved from 0.03783 to 0.03777, saving model to best_model.h5\n",
            "\n",
            "Epoch 836: val_loss improved from 0.03777 to 0.03772, saving model to best_model.h5\n",
            "\n",
            "Epoch 837: val_loss improved from 0.03772 to 0.03767, saving model to best_model.h5\n",
            "\n",
            "Epoch 838: val_loss improved from 0.03767 to 0.03762, saving model to best_model.h5\n",
            "\n",
            "Epoch 839: val_loss improved from 0.03762 to 0.03756, saving model to best_model.h5\n",
            "\n",
            "Epoch 840: val_loss improved from 0.03756 to 0.03750, saving model to best_model.h5\n",
            "\n",
            "Epoch 841: val_loss improved from 0.03750 to 0.03745, saving model to best_model.h5\n",
            "\n",
            "Epoch 842: val_loss improved from 0.03745 to 0.03739, saving model to best_model.h5\n",
            "\n",
            "Epoch 843: val_loss improved from 0.03739 to 0.03734, saving model to best_model.h5\n",
            "\n",
            "Epoch 844: val_loss improved from 0.03734 to 0.03728, saving model to best_model.h5\n",
            "\n",
            "Epoch 845: val_loss improved from 0.03728 to 0.03723, saving model to best_model.h5\n",
            "\n",
            "Epoch 846: val_loss improved from 0.03723 to 0.03717, saving model to best_model.h5\n",
            "\n",
            "Epoch 847: val_loss improved from 0.03717 to 0.03711, saving model to best_model.h5\n",
            "\n",
            "Epoch 848: val_loss improved from 0.03711 to 0.03705, saving model to best_model.h5\n",
            "\n",
            "Epoch 849: val_loss improved from 0.03705 to 0.03699, saving model to best_model.h5\n",
            "\n",
            "Epoch 850: val_loss improved from 0.03699 to 0.03693, saving model to best_model.h5\n",
            "\n",
            "Epoch 851: val_loss improved from 0.03693 to 0.03687, saving model to best_model.h5\n",
            "\n",
            "Epoch 852: val_loss improved from 0.03687 to 0.03682, saving model to best_model.h5\n",
            "\n",
            "Epoch 853: val_loss improved from 0.03682 to 0.03676, saving model to best_model.h5\n",
            "\n",
            "Epoch 854: val_loss improved from 0.03676 to 0.03670, saving model to best_model.h5\n",
            "\n",
            "Epoch 855: val_loss improved from 0.03670 to 0.03663, saving model to best_model.h5\n",
            "\n",
            "Epoch 856: val_loss improved from 0.03663 to 0.03656, saving model to best_model.h5\n",
            "\n",
            "Epoch 857: val_loss improved from 0.03656 to 0.03650, saving model to best_model.h5\n",
            "\n",
            "Epoch 858: val_loss improved from 0.03650 to 0.03642, saving model to best_model.h5\n",
            "\n",
            "Epoch 859: val_loss improved from 0.03642 to 0.03636, saving model to best_model.h5\n",
            "\n",
            "Epoch 860: val_loss improved from 0.03636 to 0.03630, saving model to best_model.h5\n",
            "\n",
            "Epoch 861: val_loss improved from 0.03630 to 0.03624, saving model to best_model.h5\n",
            "\n",
            "Epoch 862: val_loss improved from 0.03624 to 0.03618, saving model to best_model.h5\n",
            "\n",
            "Epoch 863: val_loss improved from 0.03618 to 0.03612, saving model to best_model.h5\n",
            "\n",
            "Epoch 864: val_loss improved from 0.03612 to 0.03606, saving model to best_model.h5\n",
            "\n",
            "Epoch 865: val_loss improved from 0.03606 to 0.03599, saving model to best_model.h5\n",
            "\n",
            "Epoch 866: val_loss improved from 0.03599 to 0.03592, saving model to best_model.h5\n",
            "\n",
            "Epoch 867: val_loss improved from 0.03592 to 0.03585, saving model to best_model.h5\n",
            "\n",
            "Epoch 868: val_loss improved from 0.03585 to 0.03579, saving model to best_model.h5\n",
            "\n",
            "Epoch 869: val_loss improved from 0.03579 to 0.03573, saving model to best_model.h5\n",
            "\n",
            "Epoch 870: val_loss improved from 0.03573 to 0.03567, saving model to best_model.h5\n",
            "\n",
            "Epoch 871: val_loss improved from 0.03567 to 0.03560, saving model to best_model.h5\n",
            "\n",
            "Epoch 872: val_loss improved from 0.03560 to 0.03554, saving model to best_model.h5\n",
            "\n",
            "Epoch 873: val_loss improved from 0.03554 to 0.03548, saving model to best_model.h5\n",
            "\n",
            "Epoch 874: val_loss improved from 0.03548 to 0.03541, saving model to best_model.h5\n",
            "\n",
            "Epoch 875: val_loss improved from 0.03541 to 0.03534, saving model to best_model.h5\n",
            "\n",
            "Epoch 876: val_loss improved from 0.03534 to 0.03528, saving model to best_model.h5\n",
            "\n",
            "Epoch 877: val_loss improved from 0.03528 to 0.03522, saving model to best_model.h5\n",
            "\n",
            "Epoch 878: val_loss improved from 0.03522 to 0.03516, saving model to best_model.h5\n",
            "\n",
            "Epoch 879: val_loss improved from 0.03516 to 0.03510, saving model to best_model.h5\n",
            "\n",
            "Epoch 880: val_loss improved from 0.03510 to 0.03503, saving model to best_model.h5\n",
            "\n",
            "Epoch 881: val_loss improved from 0.03503 to 0.03497, saving model to best_model.h5\n",
            "\n",
            "Epoch 882: val_loss improved from 0.03497 to 0.03491, saving model to best_model.h5\n",
            "\n",
            "Epoch 883: val_loss improved from 0.03491 to 0.03484, saving model to best_model.h5\n",
            "\n",
            "Epoch 884: val_loss improved from 0.03484 to 0.03478, saving model to best_model.h5\n",
            "\n",
            "Epoch 885: val_loss improved from 0.03478 to 0.03471, saving model to best_model.h5\n",
            "\n",
            "Epoch 886: val_loss improved from 0.03471 to 0.03465, saving model to best_model.h5\n",
            "\n",
            "Epoch 887: val_loss improved from 0.03465 to 0.03459, saving model to best_model.h5\n",
            "\n",
            "Epoch 888: val_loss improved from 0.03459 to 0.03453, saving model to best_model.h5\n",
            "\n",
            "Epoch 889: val_loss improved from 0.03453 to 0.03447, saving model to best_model.h5\n",
            "\n",
            "Epoch 890: val_loss improved from 0.03447 to 0.03440, saving model to best_model.h5\n",
            "\n",
            "Epoch 891: val_loss improved from 0.03440 to 0.03433, saving model to best_model.h5\n",
            "\n",
            "Epoch 892: val_loss improved from 0.03433 to 0.03427, saving model to best_model.h5\n",
            "\n",
            "Epoch 893: val_loss improved from 0.03427 to 0.03421, saving model to best_model.h5\n",
            "\n",
            "Epoch 894: val_loss improved from 0.03421 to 0.03417, saving model to best_model.h5\n",
            "\n",
            "Epoch 895: val_loss improved from 0.03417 to 0.03412, saving model to best_model.h5\n",
            "\n",
            "Epoch 896: val_loss improved from 0.03412 to 0.03407, saving model to best_model.h5\n",
            "\n",
            "Epoch 897: val_loss improved from 0.03407 to 0.03402, saving model to best_model.h5\n",
            "\n",
            "Epoch 898: val_loss improved from 0.03402 to 0.03396, saving model to best_model.h5\n",
            "\n",
            "Epoch 899: val_loss improved from 0.03396 to 0.03392, saving model to best_model.h5\n",
            "\n",
            "Epoch 900: val_loss improved from 0.03392 to 0.03387, saving model to best_model.h5\n",
            "\n",
            "Epoch 901: val_loss improved from 0.03387 to 0.03382, saving model to best_model.h5\n",
            "\n",
            "Epoch 902: val_loss improved from 0.03382 to 0.03377, saving model to best_model.h5\n",
            "\n",
            "Epoch 903: val_loss improved from 0.03377 to 0.03372, saving model to best_model.h5\n",
            "\n",
            "Epoch 904: val_loss improved from 0.03372 to 0.03366, saving model to best_model.h5\n",
            "\n",
            "Epoch 905: val_loss improved from 0.03366 to 0.03361, saving model to best_model.h5\n",
            "\n",
            "Epoch 906: val_loss improved from 0.03361 to 0.03356, saving model to best_model.h5\n",
            "\n",
            "Epoch 907: val_loss improved from 0.03356 to 0.03351, saving model to best_model.h5\n",
            "\n",
            "Epoch 908: val_loss improved from 0.03351 to 0.03345, saving model to best_model.h5\n",
            "\n",
            "Epoch 909: val_loss improved from 0.03345 to 0.03340, saving model to best_model.h5\n",
            "\n",
            "Epoch 910: val_loss improved from 0.03340 to 0.03334, saving model to best_model.h5\n",
            "\n",
            "Epoch 911: val_loss improved from 0.03334 to 0.03329, saving model to best_model.h5\n",
            "\n",
            "Epoch 912: val_loss improved from 0.03329 to 0.03323, saving model to best_model.h5\n",
            "\n",
            "Epoch 913: val_loss improved from 0.03323 to 0.03318, saving model to best_model.h5\n",
            "\n",
            "Epoch 914: val_loss improved from 0.03318 to 0.03313, saving model to best_model.h5\n",
            "\n",
            "Epoch 915: val_loss improved from 0.03313 to 0.03307, saving model to best_model.h5\n",
            "\n",
            "Epoch 916: val_loss improved from 0.03307 to 0.03303, saving model to best_model.h5\n",
            "\n",
            "Epoch 917: val_loss improved from 0.03303 to 0.03299, saving model to best_model.h5\n",
            "\n",
            "Epoch 918: val_loss improved from 0.03299 to 0.03295, saving model to best_model.h5\n",
            "\n",
            "Epoch 919: val_loss improved from 0.03295 to 0.03291, saving model to best_model.h5\n",
            "\n",
            "Epoch 920: val_loss improved from 0.03291 to 0.03286, saving model to best_model.h5\n",
            "\n",
            "Epoch 921: val_loss improved from 0.03286 to 0.03281, saving model to best_model.h5\n",
            "\n",
            "Epoch 922: val_loss improved from 0.03281 to 0.03276, saving model to best_model.h5\n",
            "\n",
            "Epoch 923: val_loss improved from 0.03276 to 0.03270, saving model to best_model.h5\n",
            "\n",
            "Epoch 924: val_loss improved from 0.03270 to 0.03265, saving model to best_model.h5\n",
            "\n",
            "Epoch 925: val_loss improved from 0.03265 to 0.03261, saving model to best_model.h5\n",
            "\n",
            "Epoch 926: val_loss improved from 0.03261 to 0.03256, saving model to best_model.h5\n",
            "\n",
            "Epoch 927: val_loss improved from 0.03256 to 0.03251, saving model to best_model.h5\n",
            "\n",
            "Epoch 928: val_loss improved from 0.03251 to 0.03246, saving model to best_model.h5\n",
            "\n",
            "Epoch 929: val_loss improved from 0.03246 to 0.03241, saving model to best_model.h5\n",
            "\n",
            "Epoch 930: val_loss improved from 0.03241 to 0.03235, saving model to best_model.h5\n",
            "\n",
            "Epoch 931: val_loss improved from 0.03235 to 0.03230, saving model to best_model.h5\n",
            "\n",
            "Epoch 932: val_loss improved from 0.03230 to 0.03225, saving model to best_model.h5\n",
            "\n",
            "Epoch 933: val_loss improved from 0.03225 to 0.03219, saving model to best_model.h5\n",
            "\n",
            "Epoch 934: val_loss improved from 0.03219 to 0.03213, saving model to best_model.h5\n",
            "\n",
            "Epoch 935: val_loss improved from 0.03213 to 0.03208, saving model to best_model.h5\n",
            "\n",
            "Epoch 936: val_loss improved from 0.03208 to 0.03202, saving model to best_model.h5\n",
            "\n",
            "Epoch 937: val_loss improved from 0.03202 to 0.03197, saving model to best_model.h5\n",
            "\n",
            "Epoch 938: val_loss improved from 0.03197 to 0.03192, saving model to best_model.h5\n",
            "\n",
            "Epoch 939: val_loss improved from 0.03192 to 0.03187, saving model to best_model.h5\n",
            "\n",
            "Epoch 940: val_loss improved from 0.03187 to 0.03182, saving model to best_model.h5\n",
            "\n",
            "Epoch 941: val_loss improved from 0.03182 to 0.03176, saving model to best_model.h5\n",
            "\n",
            "Epoch 942: val_loss improved from 0.03176 to 0.03170, saving model to best_model.h5\n",
            "\n",
            "Epoch 943: val_loss improved from 0.03170 to 0.03164, saving model to best_model.h5\n",
            "\n",
            "Epoch 944: val_loss improved from 0.03164 to 0.03160, saving model to best_model.h5\n",
            "\n",
            "Epoch 945: val_loss improved from 0.03160 to 0.03155, saving model to best_model.h5\n",
            "\n",
            "Epoch 946: val_loss improved from 0.03155 to 0.03149, saving model to best_model.h5\n",
            "\n",
            "Epoch 947: val_loss improved from 0.03149 to 0.03144, saving model to best_model.h5\n",
            "\n",
            "Epoch 948: val_loss improved from 0.03144 to 0.03138, saving model to best_model.h5\n",
            "\n",
            "Epoch 949: val_loss improved from 0.03138 to 0.03132, saving model to best_model.h5\n",
            "\n",
            "Epoch 950: val_loss improved from 0.03132 to 0.03127, saving model to best_model.h5\n",
            "\n",
            "Epoch 951: val_loss improved from 0.03127 to 0.03122, saving model to best_model.h5\n",
            "\n",
            "Epoch 952: val_loss improved from 0.03122 to 0.03117, saving model to best_model.h5\n",
            "\n",
            "Epoch 953: val_loss improved from 0.03117 to 0.03113, saving model to best_model.h5\n",
            "\n",
            "Epoch 954: val_loss improved from 0.03113 to 0.03107, saving model to best_model.h5\n",
            "\n",
            "Epoch 955: val_loss improved from 0.03107 to 0.03102, saving model to best_model.h5\n",
            "\n",
            "Epoch 956: val_loss improved from 0.03102 to 0.03096, saving model to best_model.h5\n",
            "\n",
            "Epoch 957: val_loss improved from 0.03096 to 0.03090, saving model to best_model.h5\n",
            "\n",
            "Epoch 958: val_loss improved from 0.03090 to 0.03084, saving model to best_model.h5\n",
            "\n",
            "Epoch 959: val_loss improved from 0.03084 to 0.03078, saving model to best_model.h5\n",
            "\n",
            "Epoch 960: val_loss improved from 0.03078 to 0.03072, saving model to best_model.h5\n",
            "\n",
            "Epoch 961: val_loss improved from 0.03072 to 0.03067, saving model to best_model.h5\n",
            "\n",
            "Epoch 962: val_loss improved from 0.03067 to 0.03063, saving model to best_model.h5\n",
            "\n",
            "Epoch 963: val_loss improved from 0.03063 to 0.03058, saving model to best_model.h5\n",
            "\n",
            "Epoch 964: val_loss improved from 0.03058 to 0.03053, saving model to best_model.h5\n",
            "\n",
            "Epoch 965: val_loss improved from 0.03053 to 0.03047, saving model to best_model.h5\n",
            "\n",
            "Epoch 966: val_loss improved from 0.03047 to 0.03041, saving model to best_model.h5\n",
            "\n",
            "Epoch 967: val_loss improved from 0.03041 to 0.03035, saving model to best_model.h5\n",
            "\n",
            "Epoch 968: val_loss improved from 0.03035 to 0.03029, saving model to best_model.h5\n",
            "\n",
            "Epoch 969: val_loss improved from 0.03029 to 0.03024, saving model to best_model.h5\n",
            "\n",
            "Epoch 970: val_loss improved from 0.03024 to 0.03019, saving model to best_model.h5\n",
            "\n",
            "Epoch 971: val_loss improved from 0.03019 to 0.03014, saving model to best_model.h5\n",
            "\n",
            "Epoch 972: val_loss improved from 0.03014 to 0.03009, saving model to best_model.h5\n",
            "\n",
            "Epoch 973: val_loss improved from 0.03009 to 0.03004, saving model to best_model.h5\n",
            "\n",
            "Epoch 974: val_loss improved from 0.03004 to 0.02998, saving model to best_model.h5\n",
            "\n",
            "Epoch 975: val_loss improved from 0.02998 to 0.02992, saving model to best_model.h5\n",
            "\n",
            "Epoch 976: val_loss improved from 0.02992 to 0.02986, saving model to best_model.h5\n",
            "\n",
            "Epoch 977: val_loss improved from 0.02986 to 0.02980, saving model to best_model.h5\n",
            "\n",
            "Epoch 978: val_loss improved from 0.02980 to 0.02975, saving model to best_model.h5\n",
            "\n",
            "Epoch 979: val_loss improved from 0.02975 to 0.02969, saving model to best_model.h5\n",
            "\n",
            "Epoch 980: val_loss improved from 0.02969 to 0.02965, saving model to best_model.h5\n",
            "\n",
            "Epoch 981: val_loss improved from 0.02965 to 0.02960, saving model to best_model.h5\n",
            "\n",
            "Epoch 982: val_loss improved from 0.02960 to 0.02955, saving model to best_model.h5\n",
            "\n",
            "Epoch 983: val_loss improved from 0.02955 to 0.02949, saving model to best_model.h5\n",
            "\n",
            "Epoch 984: val_loss improved from 0.02949 to 0.02944, saving model to best_model.h5\n",
            "\n",
            "Epoch 985: val_loss improved from 0.02944 to 0.02938, saving model to best_model.h5\n",
            "\n",
            "Epoch 986: val_loss improved from 0.02938 to 0.02932, saving model to best_model.h5\n",
            "\n",
            "Epoch 987: val_loss improved from 0.02932 to 0.02926, saving model to best_model.h5\n",
            "\n",
            "Epoch 988: val_loss improved from 0.02926 to 0.02921, saving model to best_model.h5\n",
            "\n",
            "Epoch 989: val_loss improved from 0.02921 to 0.02916, saving model to best_model.h5\n",
            "\n",
            "Epoch 990: val_loss improved from 0.02916 to 0.02911, saving model to best_model.h5\n",
            "\n",
            "Epoch 991: val_loss improved from 0.02911 to 0.02905, saving model to best_model.h5\n",
            "\n",
            "Epoch 992: val_loss improved from 0.02905 to 0.02900, saving model to best_model.h5\n",
            "\n",
            "Epoch 993: val_loss improved from 0.02900 to 0.02895, saving model to best_model.h5\n",
            "\n",
            "Epoch 994: val_loss improved from 0.02895 to 0.02886, saving model to best_model.h5\n",
            "\n",
            "Epoch 995: val_loss improved from 0.02886 to 0.02873, saving model to best_model.h5\n",
            "\n",
            "Epoch 996: val_loss improved from 0.02873 to 0.02858, saving model to best_model.h5\n",
            "\n",
            "Epoch 997: val_loss improved from 0.02858 to 0.02840, saving model to best_model.h5\n",
            "\n",
            "Epoch 998: val_loss improved from 0.02840 to 0.02826, saving model to best_model.h5\n",
            "\n",
            "Epoch 999: val_loss improved from 0.02826 to 0.02816, saving model to best_model.h5\n",
            "\n",
            "Epoch 1000: val_loss improved from 0.02816 to 0.02808, saving model to best_model.h5\n",
            "\n",
            "Epoch 1001: val_loss improved from 0.02808 to 0.02803, saving model to best_model.h5\n",
            "\n",
            "Epoch 1002: val_loss improved from 0.02803 to 0.02800, saving model to best_model.h5\n",
            "\n",
            "Epoch 1003: val_loss improved from 0.02800 to 0.02798, saving model to best_model.h5\n",
            "\n",
            "Epoch 1004: val_loss did not improve from 0.02798\n",
            "\n",
            "Epoch 1005: val_loss did not improve from 0.02798\n",
            "\n",
            "Epoch 1006: val_loss did not improve from 0.02798\n",
            "\n",
            "Epoch 1007: val_loss did not improve from 0.02798\n",
            "\n",
            "Epoch 1008: val_loss did not improve from 0.02798\n",
            "\n",
            "Epoch 1009: val_loss improved from 0.02798 to 0.02794, saving model to best_model.h5\n",
            "\n",
            "Epoch 1010: val_loss improved from 0.02794 to 0.02782, saving model to best_model.h5\n",
            "\n",
            "Epoch 1011: val_loss improved from 0.02782 to 0.02772, saving model to best_model.h5\n",
            "\n",
            "Epoch 1012: val_loss improved from 0.02772 to 0.02763, saving model to best_model.h5\n",
            "\n",
            "Epoch 1013: val_loss improved from 0.02763 to 0.02756, saving model to best_model.h5\n",
            "\n",
            "Epoch 1014: val_loss improved from 0.02756 to 0.02751, saving model to best_model.h5\n",
            "\n",
            "Epoch 1015: val_loss improved from 0.02751 to 0.02746, saving model to best_model.h5\n",
            "\n",
            "Epoch 1016: val_loss improved from 0.02746 to 0.02742, saving model to best_model.h5\n",
            "\n",
            "Epoch 1017: val_loss improved from 0.02742 to 0.02740, saving model to best_model.h5\n",
            "\n",
            "Epoch 1018: val_loss improved from 0.02740 to 0.02738, saving model to best_model.h5\n",
            "\n",
            "Epoch 1019: val_loss improved from 0.02738 to 0.02732, saving model to best_model.h5\n",
            "\n",
            "Epoch 1020: val_loss improved from 0.02732 to 0.02723, saving model to best_model.h5\n",
            "\n",
            "Epoch 1021: val_loss improved from 0.02723 to 0.02716, saving model to best_model.h5\n",
            "\n",
            "Epoch 1022: val_loss improved from 0.02716 to 0.02711, saving model to best_model.h5\n",
            "\n",
            "Epoch 1023: val_loss improved from 0.02711 to 0.02708, saving model to best_model.h5\n",
            "\n",
            "Epoch 1024: val_loss improved from 0.02708 to 0.02706, saving model to best_model.h5\n",
            "\n",
            "Epoch 1025: val_loss improved from 0.02706 to 0.02702, saving model to best_model.h5\n",
            "\n",
            "Epoch 1026: val_loss improved from 0.02702 to 0.02694, saving model to best_model.h5\n",
            "\n",
            "Epoch 1027: val_loss improved from 0.02694 to 0.02688, saving model to best_model.h5\n",
            "\n",
            "Epoch 1028: val_loss improved from 0.02688 to 0.02684, saving model to best_model.h5\n",
            "\n",
            "Epoch 1029: val_loss improved from 0.02684 to 0.02682, saving model to best_model.h5\n",
            "\n",
            "Epoch 1030: val_loss improved from 0.02682 to 0.02680, saving model to best_model.h5\n",
            "\n",
            "Epoch 1031: val_loss improved from 0.02680 to 0.02676, saving model to best_model.h5\n",
            "\n",
            "Epoch 1032: val_loss improved from 0.02676 to 0.02669, saving model to best_model.h5\n",
            "\n",
            "Epoch 1033: val_loss improved from 0.02669 to 0.02665, saving model to best_model.h5\n",
            "\n",
            "Epoch 1034: val_loss improved from 0.02665 to 0.02662, saving model to best_model.h5\n",
            "\n",
            "Epoch 1035: val_loss improved from 0.02662 to 0.02660, saving model to best_model.h5\n",
            "\n",
            "Epoch 1036: val_loss improved from 0.02660 to 0.02659, saving model to best_model.h5\n",
            "\n",
            "Epoch 1037: val_loss did not improve from 0.02659\n",
            "\n",
            "Epoch 1038: val_loss improved from 0.02659 to 0.02657, saving model to best_model.h5\n",
            "\n",
            "Epoch 1039: val_loss improved from 0.02657 to 0.02650, saving model to best_model.h5\n",
            "\n",
            "Epoch 1040: val_loss improved from 0.02650 to 0.02641, saving model to best_model.h5\n",
            "\n",
            "Epoch 1041: val_loss improved from 0.02641 to 0.02634, saving model to best_model.h5\n",
            "\n",
            "Epoch 1042: val_loss improved from 0.02634 to 0.02629, saving model to best_model.h5\n",
            "\n",
            "Epoch 1043: val_loss improved from 0.02629 to 0.02626, saving model to best_model.h5\n",
            "\n",
            "Epoch 1044: val_loss improved from 0.02626 to 0.02625, saving model to best_model.h5\n",
            "\n",
            "Epoch 1045: val_loss improved from 0.02625 to 0.02624, saving model to best_model.h5\n",
            "\n",
            "Epoch 1046: val_loss did not improve from 0.02624\n",
            "\n",
            "Epoch 1047: val_loss did not improve from 0.02624\n",
            "\n",
            "Epoch 1048: val_loss improved from 0.02624 to 0.02623, saving model to best_model.h5\n",
            "\n",
            "Epoch 1049: val_loss improved from 0.02623 to 0.02618, saving model to best_model.h5\n",
            "\n",
            "Epoch 1050: val_loss improved from 0.02618 to 0.02610, saving model to best_model.h5\n",
            "\n",
            "Epoch 1051: val_loss improved from 0.02610 to 0.02603, saving model to best_model.h5\n",
            "\n",
            "Epoch 1052: val_loss improved from 0.02603 to 0.02598, saving model to best_model.h5\n",
            "\n",
            "Epoch 1053: val_loss improved from 0.02598 to 0.02594, saving model to best_model.h5\n",
            "\n",
            "Epoch 1054: val_loss improved from 0.02594 to 0.02593, saving model to best_model.h5\n",
            "\n",
            "Epoch 1055: val_loss did not improve from 0.02593\n",
            "\n",
            "Epoch 1056: val_loss improved from 0.02593 to 0.02590, saving model to best_model.h5\n",
            "\n",
            "Epoch 1057: val_loss improved from 0.02590 to 0.02584, saving model to best_model.h5\n",
            "\n",
            "Epoch 1058: val_loss improved from 0.02584 to 0.02579, saving model to best_model.h5\n",
            "\n",
            "Epoch 1059: val_loss improved from 0.02579 to 0.02576, saving model to best_model.h5\n",
            "\n",
            "Epoch 1060: val_loss improved from 0.02576 to 0.02574, saving model to best_model.h5\n",
            "\n",
            "Epoch 1061: val_loss improved from 0.02574 to 0.02570, saving model to best_model.h5\n",
            "\n",
            "Epoch 1062: val_loss improved from 0.02570 to 0.02568, saving model to best_model.h5\n",
            "\n",
            "Epoch 1063: val_loss improved from 0.02568 to 0.02562, saving model to best_model.h5\n",
            "\n",
            "Epoch 1064: val_loss improved from 0.02562 to 0.02559, saving model to best_model.h5\n",
            "\n",
            "Epoch 1065: val_loss improved from 0.02559 to 0.02556, saving model to best_model.h5\n",
            "\n",
            "Epoch 1066: val_loss improved from 0.02556 to 0.02555, saving model to best_model.h5\n",
            "\n",
            "Epoch 1067: val_loss improved from 0.02555 to 0.02551, saving model to best_model.h5\n",
            "\n",
            "Epoch 1068: val_loss improved from 0.02551 to 0.02545, saving model to best_model.h5\n",
            "\n",
            "Epoch 1069: val_loss improved from 0.02545 to 0.02541, saving model to best_model.h5\n",
            "\n",
            "Epoch 1070: val_loss improved from 0.02541 to 0.02538, saving model to best_model.h5\n",
            "\n",
            "Epoch 1071: val_loss improved from 0.02538 to 0.02536, saving model to best_model.h5\n",
            "\n",
            "Epoch 1072: val_loss improved from 0.02536 to 0.02535, saving model to best_model.h5\n",
            "\n",
            "Epoch 1073: val_loss improved from 0.02535 to 0.02532, saving model to best_model.h5\n",
            "\n",
            "Epoch 1074: val_loss improved from 0.02532 to 0.02525, saving model to best_model.h5\n",
            "\n",
            "Epoch 1075: val_loss improved from 0.02525 to 0.02521, saving model to best_model.h5\n",
            "\n",
            "Epoch 1076: val_loss improved from 0.02521 to 0.02518, saving model to best_model.h5\n",
            "\n",
            "Epoch 1077: val_loss improved from 0.02518 to 0.02516, saving model to best_model.h5\n",
            "\n",
            "Epoch 1078: val_loss improved from 0.02516 to 0.02516, saving model to best_model.h5\n",
            "\n",
            "Epoch 1079: val_loss improved from 0.02516 to 0.02512, saving model to best_model.h5\n",
            "\n",
            "Epoch 1080: val_loss improved from 0.02512 to 0.02506, saving model to best_model.h5\n",
            "\n",
            "Epoch 1081: val_loss improved from 0.02506 to 0.02497, saving model to best_model.h5\n",
            "\n",
            "Epoch 1082: val_loss improved from 0.02497 to 0.02491, saving model to best_model.h5\n",
            "\n",
            "Epoch 1083: val_loss improved from 0.02491 to 0.02486, saving model to best_model.h5\n",
            "\n",
            "Epoch 1084: val_loss improved from 0.02486 to 0.02483, saving model to best_model.h5\n",
            "\n",
            "Epoch 1085: val_loss improved from 0.02483 to 0.02482, saving model to best_model.h5\n",
            "\n",
            "Epoch 1086: val_loss did not improve from 0.02482\n",
            "\n",
            "Epoch 1087: val_loss did not improve from 0.02482\n",
            "\n",
            "Epoch 1088: val_loss did not improve from 0.02482\n",
            "\n",
            "Epoch 1089: val_loss improved from 0.02482 to 0.02478, saving model to best_model.h5\n",
            "\n",
            "Epoch 1090: val_loss improved from 0.02478 to 0.02470, saving model to best_model.h5\n",
            "\n",
            "Epoch 1091: val_loss improved from 0.02470 to 0.02463, saving model to best_model.h5\n",
            "\n",
            "Epoch 1092: val_loss improved from 0.02463 to 0.02459, saving model to best_model.h5\n",
            "\n",
            "Epoch 1093: val_loss improved from 0.02459 to 0.02457, saving model to best_model.h5\n",
            "\n",
            "Epoch 1094: val_loss improved from 0.02457 to 0.02455, saving model to best_model.h5\n",
            "\n",
            "Epoch 1095: val_loss improved from 0.02455 to 0.02455, saving model to best_model.h5\n",
            "\n",
            "Epoch 1096: val_loss improved from 0.02455 to 0.02451, saving model to best_model.h5\n",
            "\n",
            "Epoch 1097: val_loss improved from 0.02451 to 0.02445, saving model to best_model.h5\n",
            "\n",
            "Epoch 1098: val_loss improved from 0.02445 to 0.02436, saving model to best_model.h5\n",
            "\n",
            "Epoch 1099: val_loss improved from 0.02436 to 0.02430, saving model to best_model.h5\n",
            "\n",
            "Epoch 1100: val_loss improved from 0.02430 to 0.02426, saving model to best_model.h5\n",
            "\n",
            "Epoch 1101: val_loss improved from 0.02426 to 0.02423, saving model to best_model.h5\n",
            "\n",
            "Epoch 1102: val_loss improved from 0.02423 to 0.02423, saving model to best_model.h5\n",
            "\n",
            "Epoch 1103: val_loss did not improve from 0.02423\n",
            "\n",
            "Epoch 1104: val_loss did not improve from 0.02423\n",
            "\n",
            "Epoch 1105: val_loss improved from 0.02423 to 0.02421, saving model to best_model.h5\n",
            "\n",
            "Epoch 1106: val_loss improved from 0.02421 to 0.02415, saving model to best_model.h5\n",
            "\n",
            "Epoch 1107: val_loss improved from 0.02415 to 0.02406, saving model to best_model.h5\n",
            "\n",
            "Epoch 1108: val_loss improved from 0.02406 to 0.02396, saving model to best_model.h5\n",
            "\n",
            "Epoch 1109: val_loss improved from 0.02396 to 0.02388, saving model to best_model.h5\n",
            "\n",
            "Epoch 1110: val_loss improved from 0.02388 to 0.02383, saving model to best_model.h5\n",
            "\n",
            "Epoch 1111: val_loss improved from 0.02383 to 0.02380, saving model to best_model.h5\n",
            "\n",
            "Epoch 1112: val_loss improved from 0.02380 to 0.02379, saving model to best_model.h5\n",
            "\n",
            "Epoch 1113: val_loss did not improve from 0.02379\n",
            "\n",
            "Epoch 1114: val_loss did not improve from 0.02379\n",
            "\n",
            "Epoch 1115: val_loss did not improve from 0.02379\n",
            "\n",
            "Epoch 1116: val_loss did not improve from 0.02379\n",
            "\n",
            "Epoch 1117: val_loss improved from 0.02379 to 0.02376, saving model to best_model.h5\n",
            "\n",
            "Epoch 1118: val_loss improved from 0.02376 to 0.02368, saving model to best_model.h5\n",
            "\n",
            "Epoch 1119: val_loss improved from 0.02368 to 0.02361, saving model to best_model.h5\n",
            "\n",
            "Epoch 1120: val_loss improved from 0.02361 to 0.02355, saving model to best_model.h5\n",
            "\n",
            "Epoch 1121: val_loss improved from 0.02355 to 0.02352, saving model to best_model.h5\n",
            "\n",
            "Epoch 1122: val_loss improved from 0.02352 to 0.02350, saving model to best_model.h5\n",
            "\n",
            "Epoch 1123: val_loss improved from 0.02350 to 0.02346, saving model to best_model.h5\n",
            "\n",
            "Epoch 1124: val_loss improved from 0.02346 to 0.02338, saving model to best_model.h5\n",
            "\n",
            "Epoch 1125: val_loss improved from 0.02338 to 0.02329, saving model to best_model.h5\n",
            "\n",
            "Epoch 1126: val_loss improved from 0.02329 to 0.02322, saving model to best_model.h5\n",
            "\n",
            "Epoch 1127: val_loss improved from 0.02322 to 0.02318, saving model to best_model.h5\n",
            "\n",
            "Epoch 1128: val_loss improved from 0.02318 to 0.02315, saving model to best_model.h5\n",
            "\n",
            "Epoch 1129: val_loss improved from 0.02315 to 0.02315, saving model to best_model.h5\n",
            "\n",
            "Epoch 1130: val_loss did not improve from 0.02315\n",
            "\n",
            "Epoch 1131: val_loss did not improve from 0.02315\n",
            "\n",
            "Epoch 1132: val_loss did not improve from 0.02315\n",
            "\n",
            "Epoch 1133: val_loss improved from 0.02315 to 0.02312, saving model to best_model.h5\n",
            "\n",
            "Epoch 1134: val_loss improved from 0.02312 to 0.02305, saving model to best_model.h5\n",
            "\n",
            "Epoch 1135: val_loss improved from 0.02305 to 0.02296, saving model to best_model.h5\n",
            "\n",
            "Epoch 1136: val_loss improved from 0.02296 to 0.02289, saving model to best_model.h5\n",
            "\n",
            "Epoch 1137: val_loss improved from 0.02289 to 0.02283, saving model to best_model.h5\n",
            "\n",
            "Epoch 1138: val_loss improved from 0.02283 to 0.02280, saving model to best_model.h5\n",
            "\n",
            "Epoch 1139: val_loss improved from 0.02280 to 0.02278, saving model to best_model.h5\n",
            "\n",
            "Epoch 1140: val_loss improved from 0.02278 to 0.02277, saving model to best_model.h5\n",
            "\n",
            "Epoch 1141: val_loss did not improve from 0.02277\n",
            "\n",
            "Epoch 1142: val_loss improved from 0.02277 to 0.02275, saving model to best_model.h5\n",
            "\n",
            "Epoch 1143: val_loss improved from 0.02275 to 0.02269, saving model to best_model.h5\n",
            "\n",
            "Epoch 1144: val_loss improved from 0.02269 to 0.02262, saving model to best_model.h5\n",
            "\n",
            "Epoch 1145: val_loss improved from 0.02262 to 0.02256, saving model to best_model.h5\n",
            "\n",
            "Epoch 1146: val_loss improved from 0.02256 to 0.02253, saving model to best_model.h5\n",
            "\n",
            "Epoch 1147: val_loss improved from 0.02253 to 0.02251, saving model to best_model.h5\n",
            "\n",
            "Epoch 1148: val_loss improved from 0.02251 to 0.02249, saving model to best_model.h5\n",
            "\n",
            "Epoch 1149: val_loss improved from 0.02249 to 0.02245, saving model to best_model.h5\n",
            "\n",
            "Epoch 1150: val_loss improved from 0.02245 to 0.02239, saving model to best_model.h5\n",
            "\n",
            "Epoch 1151: val_loss improved from 0.02239 to 0.02234, saving model to best_model.h5\n",
            "\n",
            "Epoch 1152: val_loss improved from 0.02234 to 0.02230, saving model to best_model.h5\n",
            "\n",
            "Epoch 1153: val_loss improved from 0.02230 to 0.02228, saving model to best_model.h5\n",
            "\n",
            "Epoch 1154: val_loss improved from 0.02228 to 0.02224, saving model to best_model.h5\n",
            "\n",
            "Epoch 1155: val_loss improved from 0.02224 to 0.02217, saving model to best_model.h5\n",
            "\n",
            "Epoch 1156: val_loss improved from 0.02217 to 0.02213, saving model to best_model.h5\n",
            "\n",
            "Epoch 1157: val_loss improved from 0.02213 to 0.02211, saving model to best_model.h5\n",
            "\n",
            "Epoch 1158: val_loss improved from 0.02211 to 0.02210, saving model to best_model.h5\n",
            "\n",
            "Epoch 1159: val_loss improved from 0.02210 to 0.02206, saving model to best_model.h5\n",
            "\n",
            "Epoch 1160: val_loss improved from 0.02206 to 0.02203, saving model to best_model.h5\n",
            "\n",
            "Epoch 1161: val_loss improved from 0.02203 to 0.02198, saving model to best_model.h5\n",
            "\n",
            "Epoch 1162: val_loss improved from 0.02198 to 0.02194, saving model to best_model.h5\n",
            "\n",
            "Epoch 1163: val_loss improved from 0.02194 to 0.02188, saving model to best_model.h5\n",
            "\n",
            "Epoch 1164: val_loss improved from 0.02188 to 0.02183, saving model to best_model.h5\n",
            "\n",
            "Epoch 1165: val_loss improved from 0.02183 to 0.02180, saving model to best_model.h5\n",
            "\n",
            "Epoch 1166: val_loss improved from 0.02180 to 0.02179, saving model to best_model.h5\n",
            "\n",
            "Epoch 1167: val_loss improved from 0.02179 to 0.02175, saving model to best_model.h5\n",
            "\n",
            "Epoch 1168: val_loss improved from 0.02175 to 0.02169, saving model to best_model.h5\n",
            "\n",
            "Epoch 1169: val_loss improved from 0.02169 to 0.02164, saving model to best_model.h5\n",
            "\n",
            "Epoch 1170: val_loss improved from 0.02164 to 0.02161, saving model to best_model.h5\n",
            "\n",
            "Epoch 1171: val_loss improved from 0.02161 to 0.02159, saving model to best_model.h5\n",
            "\n",
            "Epoch 1172: val_loss improved from 0.02159 to 0.02154, saving model to best_model.h5\n",
            "\n",
            "Epoch 1173: val_loss improved from 0.02154 to 0.02148, saving model to best_model.h5\n",
            "\n",
            "Epoch 1174: val_loss improved from 0.02148 to 0.02143, saving model to best_model.h5\n",
            "\n",
            "Epoch 1175: val_loss improved from 0.02143 to 0.02140, saving model to best_model.h5\n",
            "\n",
            "Epoch 1176: val_loss improved from 0.02140 to 0.02138, saving model to best_model.h5\n",
            "\n",
            "Epoch 1177: val_loss improved from 0.02138 to 0.02134, saving model to best_model.h5\n",
            "\n",
            "Epoch 1178: val_loss improved from 0.02134 to 0.02128, saving model to best_model.h5\n",
            "\n",
            "Epoch 1179: val_loss improved from 0.02128 to 0.02124, saving model to best_model.h5\n",
            "\n",
            "Epoch 1180: val_loss improved from 0.02124 to 0.02121, saving model to best_model.h5\n",
            "\n",
            "Epoch 1181: val_loss improved from 0.02121 to 0.02115, saving model to best_model.h5\n",
            "\n",
            "Epoch 1182: val_loss improved from 0.02115 to 0.02112, saving model to best_model.h5\n",
            "\n",
            "Epoch 1183: val_loss improved from 0.02112 to 0.02110, saving model to best_model.h5\n",
            "\n",
            "Epoch 1184: val_loss improved from 0.02110 to 0.02106, saving model to best_model.h5\n",
            "\n",
            "Epoch 1185: val_loss improved from 0.02106 to 0.02099, saving model to best_model.h5\n",
            "\n",
            "Epoch 1186: val_loss improved from 0.02099 to 0.02095, saving model to best_model.h5\n",
            "\n",
            "Epoch 1187: val_loss improved from 0.02095 to 0.02092, saving model to best_model.h5\n",
            "\n",
            "Epoch 1188: val_loss improved from 0.02092 to 0.02090, saving model to best_model.h5\n",
            "\n",
            "Epoch 1189: val_loss improved from 0.02090 to 0.02089, saving model to best_model.h5\n",
            "\n",
            "Epoch 1190: val_loss improved from 0.02089 to 0.02086, saving model to best_model.h5\n",
            "\n",
            "Epoch 1191: val_loss improved from 0.02086 to 0.02080, saving model to best_model.h5\n",
            "\n",
            "Epoch 1192: val_loss improved from 0.02080 to 0.02072, saving model to best_model.h5\n",
            "\n",
            "Epoch 1193: val_loss improved from 0.02072 to 0.02066, saving model to best_model.h5\n",
            "\n",
            "Epoch 1194: val_loss improved from 0.02066 to 0.02061, saving model to best_model.h5\n",
            "\n",
            "Epoch 1195: val_loss improved from 0.02061 to 0.02058, saving model to best_model.h5\n",
            "\n",
            "Epoch 1196: val_loss improved from 0.02058 to 0.02056, saving model to best_model.h5\n",
            "\n",
            "Epoch 1197: val_loss improved from 0.02056 to 0.02056, saving model to best_model.h5\n",
            "\n",
            "Epoch 1198: val_loss improved from 0.02056 to 0.02053, saving model to best_model.h5\n",
            "\n",
            "Epoch 1199: val_loss improved from 0.02053 to 0.02048, saving model to best_model.h5\n",
            "\n",
            "Epoch 1200: val_loss improved from 0.02048 to 0.02040, saving model to best_model.h5\n",
            "\n",
            "Epoch 1201: val_loss improved from 0.02040 to 0.02035, saving model to best_model.h5\n",
            "\n",
            "Epoch 1202: val_loss improved from 0.02035 to 0.02031, saving model to best_model.h5\n",
            "\n",
            "Epoch 1203: val_loss improved from 0.02031 to 0.02029, saving model to best_model.h5\n",
            "\n",
            "Epoch 1204: val_loss improved from 0.02029 to 0.02024, saving model to best_model.h5\n",
            "\n",
            "Epoch 1205: val_loss improved from 0.02024 to 0.02021, saving model to best_model.h5\n",
            "\n",
            "Epoch 1206: val_loss improved from 0.02021 to 0.02015, saving model to best_model.h5\n",
            "\n",
            "Epoch 1207: val_loss improved from 0.02015 to 0.02011, saving model to best_model.h5\n",
            "\n",
            "Epoch 1208: val_loss improved from 0.02011 to 0.02005, saving model to best_model.h5\n",
            "\n",
            "Epoch 1209: val_loss improved from 0.02005 to 0.02000, saving model to best_model.h5\n",
            "\n",
            "Epoch 1210: val_loss improved from 0.02000 to 0.01998, saving model to best_model.h5\n",
            "\n",
            "Epoch 1211: val_loss improved from 0.01998 to 0.01994, saving model to best_model.h5\n",
            "\n",
            "Epoch 1212: val_loss improved from 0.01994 to 0.01988, saving model to best_model.h5\n",
            "\n",
            "Epoch 1213: val_loss improved from 0.01988 to 0.01983, saving model to best_model.h5\n",
            "\n",
            "Epoch 1214: val_loss improved from 0.01983 to 0.01980, saving model to best_model.h5\n",
            "\n",
            "Epoch 1215: val_loss improved from 0.01980 to 0.01979, saving model to best_model.h5\n",
            "\n",
            "Epoch 1216: val_loss improved from 0.01979 to 0.01974, saving model to best_model.h5\n",
            "\n",
            "Epoch 1217: val_loss improved from 0.01974 to 0.01968, saving model to best_model.h5\n",
            "\n",
            "Epoch 1218: val_loss improved from 0.01968 to 0.01964, saving model to best_model.h5\n",
            "\n",
            "Epoch 1219: val_loss improved from 0.01964 to 0.01961, saving model to best_model.h5\n",
            "\n",
            "Epoch 1220: val_loss improved from 0.01961 to 0.01960, saving model to best_model.h5\n",
            "\n",
            "Epoch 1221: val_loss improved from 0.01960 to 0.01956, saving model to best_model.h5\n",
            "\n",
            "Epoch 1222: val_loss improved from 0.01956 to 0.01949, saving model to best_model.h5\n",
            "\n",
            "Epoch 1223: val_loss improved from 0.01949 to 0.01941, saving model to best_model.h5\n",
            "\n",
            "Epoch 1224: val_loss improved from 0.01941 to 0.01935, saving model to best_model.h5\n",
            "\n",
            "Epoch 1225: val_loss improved from 0.01935 to 0.01930, saving model to best_model.h5\n",
            "\n",
            "Epoch 1226: val_loss improved from 0.01930 to 0.01927, saving model to best_model.h5\n",
            "\n",
            "Epoch 1227: val_loss improved from 0.01927 to 0.01927, saving model to best_model.h5\n",
            "\n",
            "Epoch 1228: val_loss did not improve from 0.01927\n",
            "\n",
            "Epoch 1229: val_loss improved from 0.01927 to 0.01925, saving model to best_model.h5\n",
            "\n",
            "Epoch 1230: val_loss improved from 0.01925 to 0.01920, saving model to best_model.h5\n",
            "\n",
            "Epoch 1231: val_loss improved from 0.01920 to 0.01913, saving model to best_model.h5\n",
            "\n",
            "Epoch 1232: val_loss improved from 0.01913 to 0.01904, saving model to best_model.h5\n",
            "\n",
            "Epoch 1233: val_loss improved from 0.01904 to 0.01897, saving model to best_model.h5\n",
            "\n",
            "Epoch 1234: val_loss improved from 0.01897 to 0.01893, saving model to best_model.h5\n",
            "\n",
            "Epoch 1235: val_loss improved from 0.01893 to 0.01891, saving model to best_model.h5\n",
            "\n",
            "Epoch 1236: val_loss improved from 0.01891 to 0.01890, saving model to best_model.h5\n",
            "\n",
            "Epoch 1237: val_loss did not improve from 0.01890\n",
            "\n",
            "Epoch 1238: val_loss improved from 0.01890 to 0.01887, saving model to best_model.h5\n",
            "\n",
            "Epoch 1239: val_loss improved from 0.01887 to 0.01883, saving model to best_model.h5\n",
            "\n",
            "Epoch 1240: val_loss improved from 0.01883 to 0.01876, saving model to best_model.h5\n",
            "\n",
            "Epoch 1241: val_loss improved from 0.01876 to 0.01868, saving model to best_model.h5\n",
            "\n",
            "Epoch 1242: val_loss improved from 0.01868 to 0.01862, saving model to best_model.h5\n",
            "\n",
            "Epoch 1243: val_loss improved from 0.01862 to 0.01858, saving model to best_model.h5\n",
            "\n",
            "Epoch 1244: val_loss improved from 0.01858 to 0.01856, saving model to best_model.h5\n",
            "\n",
            "Epoch 1245: val_loss improved from 0.01856 to 0.01855, saving model to best_model.h5\n",
            "\n",
            "Epoch 1246: val_loss improved from 0.01855 to 0.01855, saving model to best_model.h5\n",
            "\n",
            "Epoch 1247: val_loss improved from 0.01855 to 0.01853, saving model to best_model.h5\n",
            "\n",
            "Epoch 1248: val_loss improved from 0.01853 to 0.01848, saving model to best_model.h5\n",
            "\n",
            "Epoch 1249: val_loss improved from 0.01848 to 0.01842, saving model to best_model.h5\n",
            "\n",
            "Epoch 1250: val_loss improved from 0.01842 to 0.01834, saving model to best_model.h5\n",
            "\n",
            "Epoch 1251: val_loss improved from 0.01834 to 0.01828, saving model to best_model.h5\n",
            "\n",
            "Epoch 1252: val_loss improved from 0.01828 to 0.01824, saving model to best_model.h5\n",
            "\n",
            "Epoch 1253: val_loss improved from 0.01824 to 0.01822, saving model to best_model.h5\n",
            "\n",
            "Epoch 1254: val_loss improved from 0.01822 to 0.01821, saving model to best_model.h5\n",
            "\n",
            "Epoch 1255: val_loss did not improve from 0.01821\n",
            "\n",
            "Epoch 1256: val_loss improved from 0.01821 to 0.01819, saving model to best_model.h5\n",
            "\n",
            "Epoch 1257: val_loss improved from 0.01819 to 0.01815, saving model to best_model.h5\n",
            "\n",
            "Epoch 1258: val_loss improved from 0.01815 to 0.01809, saving model to best_model.h5\n",
            "\n",
            "Epoch 1259: val_loss improved from 0.01809 to 0.01801, saving model to best_model.h5\n",
            "\n",
            "Epoch 1260: val_loss improved from 0.01801 to 0.01795, saving model to best_model.h5\n",
            "\n",
            "Epoch 1261: val_loss improved from 0.01795 to 0.01791, saving model to best_model.h5\n",
            "\n",
            "Epoch 1262: val_loss improved from 0.01791 to 0.01789, saving model to best_model.h5\n",
            "\n",
            "Epoch 1263: val_loss improved from 0.01789 to 0.01789, saving model to best_model.h5\n",
            "\n",
            "Epoch 1264: val_loss improved from 0.01789 to 0.01786, saving model to best_model.h5\n",
            "\n",
            "Epoch 1265: val_loss improved from 0.01786 to 0.01782, saving model to best_model.h5\n",
            "\n",
            "Epoch 1266: val_loss improved from 0.01782 to 0.01779, saving model to best_model.h5\n",
            "\n",
            "Epoch 1267: val_loss improved from 0.01779 to 0.01777, saving model to best_model.h5\n",
            "\n",
            "Epoch 1268: val_loss improved from 0.01777 to 0.01773, saving model to best_model.h5\n",
            "\n",
            "Epoch 1269: val_loss improved from 0.01773 to 0.01767, saving model to best_model.h5\n",
            "\n",
            "Epoch 1270: val_loss improved from 0.01767 to 0.01763, saving model to best_model.h5\n",
            "\n",
            "Epoch 1271: val_loss improved from 0.01763 to 0.01761, saving model to best_model.h5\n",
            "\n",
            "Epoch 1272: val_loss improved from 0.01761 to 0.01757, saving model to best_model.h5\n",
            "\n",
            "Epoch 1273: val_loss improved from 0.01757 to 0.01754, saving model to best_model.h5\n",
            "\n",
            "Epoch 1274: val_loss improved from 0.01754 to 0.01749, saving model to best_model.h5\n",
            "\n",
            "Epoch 1275: val_loss improved from 0.01749 to 0.01746, saving model to best_model.h5\n",
            "\n",
            "Epoch 1276: val_loss improved from 0.01746 to 0.01745, saving model to best_model.h5\n",
            "\n",
            "Epoch 1277: val_loss improved from 0.01745 to 0.01741, saving model to best_model.h5\n",
            "\n",
            "Epoch 1278: val_loss improved from 0.01741 to 0.01736, saving model to best_model.h5\n",
            "\n",
            "Epoch 1279: val_loss improved from 0.01736 to 0.01733, saving model to best_model.h5\n",
            "\n",
            "Epoch 1280: val_loss improved from 0.01733 to 0.01731, saving model to best_model.h5\n",
            "\n",
            "Epoch 1281: val_loss improved from 0.01731 to 0.01727, saving model to best_model.h5\n",
            "\n",
            "Epoch 1282: val_loss improved from 0.01727 to 0.01721, saving model to best_model.h5\n",
            "\n",
            "Epoch 1283: val_loss improved from 0.01721 to 0.01717, saving model to best_model.h5\n",
            "\n",
            "Epoch 1284: val_loss improved from 0.01717 to 0.01715, saving model to best_model.h5\n",
            "\n",
            "Epoch 1285: val_loss improved from 0.01715 to 0.01714, saving model to best_model.h5\n",
            "\n",
            "Epoch 1286: val_loss improved from 0.01714 to 0.01712, saving model to best_model.h5\n",
            "\n",
            "Epoch 1287: val_loss improved from 0.01712 to 0.01707, saving model to best_model.h5\n",
            "\n",
            "Epoch 1288: val_loss improved from 0.01707 to 0.01704, saving model to best_model.h5\n",
            "\n",
            "Epoch 1289: val_loss improved from 0.01704 to 0.01702, saving model to best_model.h5\n",
            "\n",
            "Epoch 1290: val_loss improved from 0.01702 to 0.01698, saving model to best_model.h5\n",
            "\n",
            "Epoch 1291: val_loss improved from 0.01698 to 0.01692, saving model to best_model.h5\n",
            "\n",
            "Epoch 1292: val_loss improved from 0.01692 to 0.01688, saving model to best_model.h5\n",
            "\n",
            "Epoch 1293: val_loss improved from 0.01688 to 0.01686, saving model to best_model.h5\n",
            "\n",
            "Epoch 1294: val_loss improved from 0.01686 to 0.01685, saving model to best_model.h5\n",
            "\n",
            "Epoch 1295: val_loss improved from 0.01685 to 0.01682, saving model to best_model.h5\n",
            "\n",
            "Epoch 1296: val_loss improved from 0.01682 to 0.01678, saving model to best_model.h5\n",
            "\n",
            "Epoch 1297: val_loss improved from 0.01678 to 0.01672, saving model to best_model.h5\n",
            "\n",
            "Epoch 1298: val_loss improved from 0.01672 to 0.01667, saving model to best_model.h5\n",
            "\n",
            "Epoch 1299: val_loss improved from 0.01667 to 0.01665, saving model to best_model.h5\n",
            "\n",
            "Epoch 1300: val_loss improved from 0.01665 to 0.01664, saving model to best_model.h5\n",
            "\n",
            "Epoch 1301: val_loss did not improve from 0.01664\n",
            "\n",
            "Epoch 1302: val_loss improved from 0.01664 to 0.01661, saving model to best_model.h5\n",
            "\n",
            "Epoch 1303: val_loss improved from 0.01661 to 0.01657, saving model to best_model.h5\n",
            "\n",
            "Epoch 1304: val_loss improved from 0.01657 to 0.01651, saving model to best_model.h5\n",
            "\n",
            "Epoch 1305: val_loss improved from 0.01651 to 0.01647, saving model to best_model.h5\n",
            "\n",
            "Epoch 1306: val_loss improved from 0.01647 to 0.01644, saving model to best_model.h5\n",
            "\n",
            "Epoch 1307: val_loss improved from 0.01644 to 0.01640, saving model to best_model.h5\n",
            "\n",
            "Epoch 1308: val_loss improved from 0.01640 to 0.01638, saving model to best_model.h5\n",
            "\n",
            "Epoch 1309: val_loss improved from 0.01638 to 0.01636, saving model to best_model.h5\n",
            "\n",
            "Epoch 1310: val_loss improved from 0.01636 to 0.01633, saving model to best_model.h5\n",
            "\n",
            "Epoch 1311: val_loss improved from 0.01633 to 0.01628, saving model to best_model.h5\n",
            "\n",
            "Epoch 1312: val_loss improved from 0.01628 to 0.01624, saving model to best_model.h5\n",
            "\n",
            "Epoch 1313: val_loss improved from 0.01624 to 0.01622, saving model to best_model.h5\n",
            "\n",
            "Epoch 1314: val_loss improved from 0.01622 to 0.01622, saving model to best_model.h5\n",
            "\n",
            "Epoch 1315: val_loss improved from 0.01622 to 0.01619, saving model to best_model.h5\n",
            "\n",
            "Epoch 1316: val_loss improved from 0.01619 to 0.01614, saving model to best_model.h5\n",
            "\n",
            "Epoch 1317: val_loss improved from 0.01614 to 0.01608, saving model to best_model.h5\n",
            "\n",
            "Epoch 1318: val_loss improved from 0.01608 to 0.01605, saving model to best_model.h5\n",
            "\n",
            "Epoch 1319: val_loss improved from 0.01605 to 0.01602, saving model to best_model.h5\n",
            "\n",
            "Epoch 1320: val_loss improved from 0.01602 to 0.01601, saving model to best_model.h5\n",
            "\n",
            "Epoch 1321: val_loss improved from 0.01601 to 0.01598, saving model to best_model.h5\n",
            "\n",
            "Epoch 1322: val_loss improved from 0.01598 to 0.01594, saving model to best_model.h5\n",
            "\n",
            "Epoch 1323: val_loss improved from 0.01594 to 0.01591, saving model to best_model.h5\n",
            "\n",
            "Epoch 1324: val_loss improved from 0.01591 to 0.01589, saving model to best_model.h5\n",
            "\n",
            "Epoch 1325: val_loss improved from 0.01589 to 0.01586, saving model to best_model.h5\n",
            "\n",
            "Epoch 1326: val_loss improved from 0.01586 to 0.01584, saving model to best_model.h5\n",
            "\n",
            "Epoch 1327: val_loss improved from 0.01584 to 0.01581, saving model to best_model.h5\n",
            "\n",
            "Epoch 1328: val_loss improved from 0.01581 to 0.01575, saving model to best_model.h5\n",
            "\n",
            "Epoch 1329: val_loss improved from 0.01575 to 0.01571, saving model to best_model.h5\n",
            "\n",
            "Epoch 1330: val_loss improved from 0.01571 to 0.01569, saving model to best_model.h5\n",
            "\n",
            "Epoch 1331: val_loss improved from 0.01569 to 0.01568, saving model to best_model.h5\n",
            "\n",
            "Epoch 1332: val_loss improved from 0.01568 to 0.01565, saving model to best_model.h5\n",
            "\n",
            "Epoch 1333: val_loss improved from 0.01565 to 0.01561, saving model to best_model.h5\n",
            "\n",
            "Epoch 1334: val_loss improved from 0.01561 to 0.01558, saving model to best_model.h5\n",
            "\n",
            "Epoch 1335: val_loss improved from 0.01558 to 0.01556, saving model to best_model.h5\n",
            "\n",
            "Epoch 1336: val_loss improved from 0.01556 to 0.01553, saving model to best_model.h5\n",
            "\n",
            "Epoch 1337: val_loss improved from 0.01553 to 0.01548, saving model to best_model.h5\n",
            "\n",
            "Epoch 1338: val_loss improved from 0.01548 to 0.01544, saving model to best_model.h5\n",
            "\n",
            "Epoch 1339: val_loss improved from 0.01544 to 0.01542, saving model to best_model.h5\n",
            "\n",
            "Epoch 1340: val_loss improved from 0.01542 to 0.01542, saving model to best_model.h5\n",
            "\n",
            "Epoch 1341: val_loss improved from 0.01542 to 0.01540, saving model to best_model.h5\n",
            "\n",
            "Epoch 1342: val_loss improved from 0.01540 to 0.01536, saving model to best_model.h5\n",
            "\n",
            "Epoch 1343: val_loss improved from 0.01536 to 0.01530, saving model to best_model.h5\n",
            "\n",
            "Epoch 1344: val_loss improved from 0.01530 to 0.01526, saving model to best_model.h5\n",
            "\n",
            "Epoch 1345: val_loss improved from 0.01526 to 0.01524, saving model to best_model.h5\n",
            "\n",
            "Epoch 1346: val_loss improved from 0.01524 to 0.01523, saving model to best_model.h5\n",
            "\n",
            "Epoch 1347: val_loss improved from 0.01523 to 0.01523, saving model to best_model.h5\n",
            "\n",
            "Epoch 1348: val_loss improved from 0.01523 to 0.01521, saving model to best_model.h5\n",
            "\n",
            "Epoch 1349: val_loss improved from 0.01521 to 0.01517, saving model to best_model.h5\n",
            "\n",
            "Epoch 1350: val_loss improved from 0.01517 to 0.01511, saving model to best_model.h5\n",
            "\n",
            "Epoch 1351: val_loss improved from 0.01511 to 0.01505, saving model to best_model.h5\n",
            "\n",
            "Epoch 1352: val_loss improved from 0.01505 to 0.01501, saving model to best_model.h5\n",
            "\n",
            "Epoch 1353: val_loss improved from 0.01501 to 0.01498, saving model to best_model.h5\n",
            "\n",
            "Epoch 1354: val_loss improved from 0.01498 to 0.01497, saving model to best_model.h5\n",
            "\n",
            "Epoch 1355: val_loss improved from 0.01497 to 0.01494, saving model to best_model.h5\n",
            "\n",
            "Epoch 1356: val_loss improved from 0.01494 to 0.01491, saving model to best_model.h5\n",
            "\n",
            "Epoch 1357: val_loss improved from 0.01491 to 0.01486, saving model to best_model.h5\n",
            "\n",
            "Epoch 1358: val_loss improved from 0.01486 to 0.01482, saving model to best_model.h5\n",
            "\n",
            "Epoch 1359: val_loss improved from 0.01482 to 0.01481, saving model to best_model.h5\n",
            "\n",
            "Epoch 1360: val_loss improved from 0.01481 to 0.01478, saving model to best_model.h5\n",
            "\n",
            "Epoch 1361: val_loss improved from 0.01478 to 0.01474, saving model to best_model.h5\n",
            "\n",
            "Epoch 1362: val_loss improved from 0.01474 to 0.01472, saving model to best_model.h5\n",
            "\n",
            "Epoch 1363: val_loss improved from 0.01472 to 0.01471, saving model to best_model.h5\n",
            "\n",
            "Epoch 1364: val_loss improved from 0.01471 to 0.01468, saving model to best_model.h5\n",
            "\n",
            "Epoch 1365: val_loss improved from 0.01468 to 0.01464, saving model to best_model.h5\n",
            "\n",
            "Epoch 1366: val_loss improved from 0.01464 to 0.01459, saving model to best_model.h5\n",
            "\n",
            "Epoch 1367: val_loss improved from 0.01459 to 0.01455, saving model to best_model.h5\n",
            "\n",
            "Epoch 1368: val_loss improved from 0.01455 to 0.01453, saving model to best_model.h5\n",
            "\n",
            "Epoch 1369: val_loss improved from 0.01453 to 0.01452, saving model to best_model.h5\n",
            "\n",
            "Epoch 1370: val_loss improved from 0.01452 to 0.01450, saving model to best_model.h5\n",
            "\n",
            "Epoch 1371: val_loss improved from 0.01450 to 0.01446, saving model to best_model.h5\n",
            "\n",
            "Epoch 1372: val_loss improved from 0.01446 to 0.01441, saving model to best_model.h5\n",
            "\n",
            "Epoch 1373: val_loss improved from 0.01441 to 0.01437, saving model to best_model.h5\n",
            "\n",
            "Epoch 1374: val_loss improved from 0.01437 to 0.01435, saving model to best_model.h5\n",
            "\n",
            "Epoch 1375: val_loss improved from 0.01435 to 0.01434, saving model to best_model.h5\n",
            "\n",
            "Epoch 1376: val_loss improved from 0.01434 to 0.01432, saving model to best_model.h5\n",
            "\n",
            "Epoch 1377: val_loss improved from 0.01432 to 0.01429, saving model to best_model.h5\n",
            "\n",
            "Epoch 1378: val_loss improved from 0.01429 to 0.01426, saving model to best_model.h5\n",
            "\n",
            "Epoch 1379: val_loss improved from 0.01426 to 0.01423, saving model to best_model.h5\n",
            "\n",
            "Epoch 1380: val_loss improved from 0.01423 to 0.01421, saving model to best_model.h5\n",
            "\n",
            "Epoch 1381: val_loss improved from 0.01421 to 0.01417, saving model to best_model.h5\n",
            "\n",
            "Epoch 1382: val_loss improved from 0.01417 to 0.01415, saving model to best_model.h5\n",
            "\n",
            "Epoch 1383: val_loss improved from 0.01415 to 0.01411, saving model to best_model.h5\n",
            "\n",
            "Epoch 1384: val_loss improved from 0.01411 to 0.01407, saving model to best_model.h5\n",
            "\n",
            "Epoch 1385: val_loss improved from 0.01407 to 0.01404, saving model to best_model.h5\n",
            "\n",
            "Epoch 1386: val_loss improved from 0.01404 to 0.01402, saving model to best_model.h5\n",
            "\n",
            "Epoch 1387: val_loss improved from 0.01402 to 0.01400, saving model to best_model.h5\n",
            "\n",
            "Epoch 1388: val_loss improved from 0.01400 to 0.01396, saving model to best_model.h5\n",
            "\n",
            "Epoch 1389: val_loss improved from 0.01396 to 0.01393, saving model to best_model.h5\n",
            "\n",
            "Epoch 1390: val_loss improved from 0.01393 to 0.01392, saving model to best_model.h5\n",
            "\n",
            "Epoch 1391: val_loss improved from 0.01392 to 0.01390, saving model to best_model.h5\n",
            "\n",
            "Epoch 1392: val_loss improved from 0.01390 to 0.01387, saving model to best_model.h5\n",
            "\n",
            "Epoch 1393: val_loss improved from 0.01387 to 0.01382, saving model to best_model.h5\n",
            "\n",
            "Epoch 1394: val_loss improved from 0.01382 to 0.01379, saving model to best_model.h5\n",
            "\n",
            "Epoch 1395: val_loss improved from 0.01379 to 0.01377, saving model to best_model.h5\n",
            "\n",
            "Epoch 1396: val_loss improved from 0.01377 to 0.01376, saving model to best_model.h5\n",
            "\n",
            "Epoch 1397: val_loss improved from 0.01376 to 0.01374, saving model to best_model.h5\n",
            "\n",
            "Epoch 1398: val_loss improved from 0.01374 to 0.01371, saving model to best_model.h5\n",
            "\n",
            "Epoch 1399: val_loss improved from 0.01371 to 0.01366, saving model to best_model.h5\n",
            "\n",
            "Epoch 1400: val_loss improved from 0.01366 to 0.01363, saving model to best_model.h5\n",
            "\n",
            "Epoch 1401: val_loss improved from 0.01363 to 0.01361, saving model to best_model.h5\n",
            "\n",
            "Epoch 1402: val_loss improved from 0.01361 to 0.01357, saving model to best_model.h5\n",
            "\n",
            "Epoch 1403: val_loss improved from 0.01357 to 0.01353, saving model to best_model.h5\n",
            "\n",
            "Epoch 1404: val_loss improved from 0.01353 to 0.01350, saving model to best_model.h5\n",
            "\n",
            "Epoch 1405: val_loss improved from 0.01350 to 0.01349, saving model to best_model.h5\n",
            "\n",
            "Epoch 1406: val_loss improved from 0.01349 to 0.01346, saving model to best_model.h5\n",
            "\n",
            "Epoch 1407: val_loss improved from 0.01346 to 0.01343, saving model to best_model.h5\n",
            "\n",
            "Epoch 1408: val_loss improved from 0.01343 to 0.01338, saving model to best_model.h5\n",
            "\n",
            "Epoch 1409: val_loss improved from 0.01338 to 0.01335, saving model to best_model.h5\n",
            "\n",
            "Epoch 1410: val_loss improved from 0.01335 to 0.01333, saving model to best_model.h5\n",
            "\n",
            "Epoch 1411: val_loss improved from 0.01333 to 0.01333, saving model to best_model.h5\n",
            "\n",
            "Epoch 1412: val_loss improved from 0.01333 to 0.01331, saving model to best_model.h5\n",
            "\n",
            "Epoch 1413: val_loss improved from 0.01331 to 0.01328, saving model to best_model.h5\n",
            "\n",
            "Epoch 1414: val_loss improved from 0.01328 to 0.01324, saving model to best_model.h5\n",
            "\n",
            "Epoch 1415: val_loss improved from 0.01324 to 0.01319, saving model to best_model.h5\n",
            "\n",
            "Epoch 1416: val_loss improved from 0.01319 to 0.01316, saving model to best_model.h5\n",
            "\n",
            "Epoch 1417: val_loss improved from 0.01316 to 0.01314, saving model to best_model.h5\n",
            "\n",
            "Epoch 1418: val_loss improved from 0.01314 to 0.01313, saving model to best_model.h5\n",
            "\n",
            "Epoch 1419: val_loss improved from 0.01313 to 0.01311, saving model to best_model.h5\n",
            "\n",
            "Epoch 1420: val_loss improved from 0.01311 to 0.01308, saving model to best_model.h5\n",
            "\n",
            "Epoch 1421: val_loss improved from 0.01308 to 0.01304, saving model to best_model.h5\n",
            "\n",
            "Epoch 1422: val_loss improved from 0.01304 to 0.01301, saving model to best_model.h5\n",
            "\n",
            "Epoch 1423: val_loss improved from 0.01301 to 0.01300, saving model to best_model.h5\n",
            "\n",
            "Epoch 1424: val_loss improved from 0.01300 to 0.01297, saving model to best_model.h5\n",
            "\n",
            "Epoch 1425: val_loss improved from 0.01297 to 0.01294, saving model to best_model.h5\n",
            "\n",
            "Epoch 1426: val_loss improved from 0.01294 to 0.01291, saving model to best_model.h5\n",
            "\n",
            "Epoch 1427: val_loss improved from 0.01291 to 0.01291, saving model to best_model.h5\n",
            "\n",
            "Epoch 1428: val_loss improved from 0.01291 to 0.01289, saving model to best_model.h5\n",
            "\n",
            "Epoch 1429: val_loss improved from 0.01289 to 0.01285, saving model to best_model.h5\n",
            "\n",
            "Epoch 1430: val_loss improved from 0.01285 to 0.01281, saving model to best_model.h5\n",
            "\n",
            "Epoch 1431: val_loss improved from 0.01281 to 0.01278, saving model to best_model.h5\n",
            "\n",
            "Epoch 1432: val_loss improved from 0.01278 to 0.01277, saving model to best_model.h5\n",
            "\n",
            "Epoch 1433: val_loss improved from 0.01277 to 0.01274, saving model to best_model.h5\n",
            "\n",
            "Epoch 1434: val_loss improved from 0.01274 to 0.01271, saving model to best_model.h5\n",
            "\n",
            "Epoch 1435: val_loss improved from 0.01271 to 0.01269, saving model to best_model.h5\n",
            "\n",
            "Epoch 1436: val_loss improved from 0.01269 to 0.01266, saving model to best_model.h5\n",
            "\n",
            "Epoch 1437: val_loss improved from 0.01266 to 0.01263, saving model to best_model.h5\n",
            "\n",
            "Epoch 1438: val_loss improved from 0.01263 to 0.01261, saving model to best_model.h5\n",
            "\n",
            "Epoch 1439: val_loss improved from 0.01261 to 0.01260, saving model to best_model.h5\n",
            "\n",
            "Epoch 1440: val_loss did not improve from 0.01260\n",
            "\n",
            "Epoch 1441: val_loss improved from 0.01260 to 0.01259, saving model to best_model.h5\n",
            "\n",
            "Epoch 1442: val_loss improved from 0.01259 to 0.01256, saving model to best_model.h5\n",
            "\n",
            "Epoch 1443: val_loss improved from 0.01256 to 0.01252, saving model to best_model.h5\n",
            "\n",
            "Epoch 1444: val_loss improved from 0.01252 to 0.01248, saving model to best_model.h5\n",
            "\n",
            "Epoch 1445: val_loss improved from 0.01248 to 0.01243, saving model to best_model.h5\n",
            "\n",
            "Epoch 1446: val_loss improved from 0.01243 to 0.01240, saving model to best_model.h5\n",
            "\n",
            "Epoch 1447: val_loss improved from 0.01240 to 0.01238, saving model to best_model.h5\n",
            "\n",
            "Epoch 1448: val_loss improved from 0.01238 to 0.01238, saving model to best_model.h5\n",
            "\n",
            "Epoch 1449: val_loss did not improve from 0.01238\n",
            "\n",
            "Epoch 1450: val_loss improved from 0.01238 to 0.01237, saving model to best_model.h5\n",
            "\n",
            "Epoch 1451: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1452: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1453: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1454: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1455: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1456: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1457: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1458: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1459: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1460: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1461: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1462: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1463: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1464: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1465: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1466: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1467: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1468: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1469: val_loss did not improve from 0.01237\n",
            "\n",
            "Epoch 1470: val_loss did not improve from 0.01237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 평가"
      ],
      "metadata": {
        "id": "9W7gPX9sG77d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model(model_path)\n",
        "best_model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjMy8eOyGBfB",
        "outputId": "cb1f053f-4049-425a-ce7d-f3f041ffd359"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 119ms/step - loss: 0.2584 - accuracy: 0.9333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2584382891654968, 0.9333333373069763]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 시각화"
      ],
      "metadata": {
        "id": "q6d13Il_HqAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_acc = hist.history['accuracy']\n",
        "y_vloss = hist.history['val_loss']\n",
        "xs = np.arange(1, len(y_acc)+1)"
      ],
      "metadata": {
        "id": "8mKtijOvHGy4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(xs, y_acc, label='train accuracy')\n",
        "plt.plot(xs, y_vloss, label='validation loss')\n",
        "plt.legend(), plt.grid()\n",
        "plt.ylim([0,1.2])\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "dB56uAesHuiX",
        "outputId": "3ff0e630-2a60-4748-a193-6931db79b5f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u575xLIFHy2A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}