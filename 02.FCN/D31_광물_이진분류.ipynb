{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 초음파 광물 데이터 - 이진 분류"
      ],
      "metadata": {
        "id": "gLiOb7yukASZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OmkBYGPPj0SV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "seed = 2023\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터 전처리"
      ],
      "metadata": {
        "id": "42Eskw63kflv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 업로드\n",
        "from google.colab import files\n",
        "up = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "6k8Sjfe1kTIQ",
        "outputId": "648fb0ae-da4c-4ffc-8ad6-e3cca1617b4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dcf6c2d4-fb59-4e32-841d-2d210b9aef1e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dcf6c2d4-fb59-4e32-841d-2d210b9aef1e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sonar.csv to sonar.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('sonar.csv', header=None)\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "yQ3AWPRSkoSI",
        "outputId": "d77a9840-0152-47a0-dd19-aaff78c86ed0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0       1       2       3       4       5       6       7       8   \\\n",
              "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
              "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
              "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
              "\n",
              "       9   ...      51      52      53      54      55      56      57  \\\n",
              "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
              "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
              "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
              "\n",
              "       58      59  60  \n",
              "0  0.0090  0.0032   R  \n",
              "1  0.0052  0.0044   R  \n",
              "2  0.0095  0.0078   R  \n",
              "\n",
              "[3 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12412f5c-9449-418e-968f-d2cf1c0176e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12412f5c-9449-418e-968f-d2cf1c0176e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12412f5c-9449-418e-968f-d2cf1c0176e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12412f5c-9449-418e-968f-d2cf1c0176e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[60].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6AfG-VRlRkQ",
        "outputId": "4cc37f8b-85cb-40ea-8558-8cb907bb30c4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M    111\n",
              "R     97\n",
              "Name: 60, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X data: scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df.iloc[:, :-1].values)     # 행 전체, 마지막열 제외한 모든 열을 넘파이 배열로 만들어 줌"
      ],
      "metadata": {
        "id": "FQBy7H23luLo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Y data: label encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "y_labeled = LabelEncoder().fit_transform(df[60].values)"
      ],
      "metadata": {
        "id": "qHaVUp8moDey"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, Test dataset 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_labeled, stratify=y_labeled, test_size=0.2, random_state=seed\n",
        ")\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W03ZBQvyppW1",
        "outputId": "35844a68-7ded-4f90-f3b8-5bc082186a83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((166, 60), (42, 60), (166,), (42,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 정의/설정/학습/평가"
      ],
      "metadata": {
        "id": "TwJBjb-vrWAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "HQa6bXzBqwp7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 1. 은닉층 2개"
      ],
      "metadata": {
        "id": "C7aEixBVsBu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential([ \n",
        "    Dense(80, input_dim=60, activation='relu'),\n",
        "    Dense(12, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfz1Jwfsr2x8",
        "outputId": "4a984437-dba0-4747-d89c-b7d3a8508b24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 80)                4880      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12)                972       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,865\n",
            "Trainable params: 5,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile('adam', 'binary_crossentropy', ['accuracy'])\n",
        "model_path1 = 'best_model1.h5'\n",
        "mc1 = ModelCheckpoint(\n",
        "    filepath=model_path1,               # 저장할 파일 이름\n",
        "    monitor='val_loss',                 # validation dataset의 loss값 기준\n",
        "    verbose=1,                          # 화면에 잔뜩 표시\n",
        "    save_best_only=True                 # best model만 저장\n",
        ")\n",
        "es1 = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=20                     # 20 epoch 동안 val_loss가 좋아지지 않으면 강제 종료\n",
        ")"
      ],
      "metadata": {
        "id": "Xz093vRtsjLc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist1 = model1.fit(X_train, y_train, validation_split=0.2,\n",
        "                   epochs=200, batch_size=100, verbose=0, \n",
        "                   callbacks=[mc1, es1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HteB8HfUtgQE",
        "outputId": "7c4d2c11-0747-4d8a-c564-c57fef1172e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 0.67009, saving model to best_model1.h5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.67009 to 0.65214, saving model to best_model1.h5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.65214 to 0.63652, saving model to best_model1.h5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.63652 to 0.62343, saving model to best_model1.h5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.62343 to 0.61150, saving model to best_model1.h5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.61150 to 0.59939, saving model to best_model1.h5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.59939 to 0.58854, saving model to best_model1.h5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.58854 to 0.57803, saving model to best_model1.h5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.57803 to 0.56736, saving model to best_model1.h5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.56736 to 0.55658, saving model to best_model1.h5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.55658 to 0.54613, saving model to best_model1.h5\n",
            "\n",
            "Epoch 12: val_loss improved from 0.54613 to 0.53493, saving model to best_model1.h5\n",
            "\n",
            "Epoch 13: val_loss improved from 0.53493 to 0.52434, saving model to best_model1.h5\n",
            "\n",
            "Epoch 14: val_loss improved from 0.52434 to 0.51358, saving model to best_model1.h5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.51358 to 0.50371, saving model to best_model1.h5\n",
            "\n",
            "Epoch 16: val_loss improved from 0.50371 to 0.49418, saving model to best_model1.h5\n",
            "\n",
            "Epoch 17: val_loss improved from 0.49418 to 0.48395, saving model to best_model1.h5\n",
            "\n",
            "Epoch 18: val_loss improved from 0.48395 to 0.47423, saving model to best_model1.h5\n",
            "\n",
            "Epoch 19: val_loss improved from 0.47423 to 0.46494, saving model to best_model1.h5\n",
            "\n",
            "Epoch 20: val_loss improved from 0.46494 to 0.45592, saving model to best_model1.h5\n",
            "\n",
            "Epoch 21: val_loss improved from 0.45592 to 0.44775, saving model to best_model1.h5\n",
            "\n",
            "Epoch 22: val_loss improved from 0.44775 to 0.44013, saving model to best_model1.h5\n",
            "\n",
            "Epoch 23: val_loss improved from 0.44013 to 0.43285, saving model to best_model1.h5\n",
            "\n",
            "Epoch 24: val_loss improved from 0.43285 to 0.42618, saving model to best_model1.h5\n",
            "\n",
            "Epoch 25: val_loss improved from 0.42618 to 0.41931, saving model to best_model1.h5\n",
            "\n",
            "Epoch 26: val_loss improved from 0.41931 to 0.41161, saving model to best_model1.h5\n",
            "\n",
            "Epoch 27: val_loss improved from 0.41161 to 0.40383, saving model to best_model1.h5\n",
            "\n",
            "Epoch 28: val_loss improved from 0.40383 to 0.39611, saving model to best_model1.h5\n",
            "\n",
            "Epoch 29: val_loss improved from 0.39611 to 0.38859, saving model to best_model1.h5\n",
            "\n",
            "Epoch 30: val_loss improved from 0.38859 to 0.38215, saving model to best_model1.h5\n",
            "\n",
            "Epoch 31: val_loss improved from 0.38215 to 0.37676, saving model to best_model1.h5\n",
            "\n",
            "Epoch 32: val_loss improved from 0.37676 to 0.37255, saving model to best_model1.h5\n",
            "\n",
            "Epoch 33: val_loss improved from 0.37255 to 0.36838, saving model to best_model1.h5\n",
            "\n",
            "Epoch 34: val_loss improved from 0.36838 to 0.36348, saving model to best_model1.h5\n",
            "\n",
            "Epoch 35: val_loss improved from 0.36348 to 0.35834, saving model to best_model1.h5\n",
            "\n",
            "Epoch 36: val_loss improved from 0.35834 to 0.35326, saving model to best_model1.h5\n",
            "\n",
            "Epoch 37: val_loss improved from 0.35326 to 0.34793, saving model to best_model1.h5\n",
            "\n",
            "Epoch 38: val_loss improved from 0.34793 to 0.34201, saving model to best_model1.h5\n",
            "\n",
            "Epoch 39: val_loss improved from 0.34201 to 0.33583, saving model to best_model1.h5\n",
            "\n",
            "Epoch 40: val_loss improved from 0.33583 to 0.32984, saving model to best_model1.h5\n",
            "\n",
            "Epoch 41: val_loss improved from 0.32984 to 0.32471, saving model to best_model1.h5\n",
            "\n",
            "Epoch 42: val_loss improved from 0.32471 to 0.31995, saving model to best_model1.h5\n",
            "\n",
            "Epoch 43: val_loss improved from 0.31995 to 0.31558, saving model to best_model1.h5\n",
            "\n",
            "Epoch 44: val_loss improved from 0.31558 to 0.31229, saving model to best_model1.h5\n",
            "\n",
            "Epoch 45: val_loss improved from 0.31229 to 0.30924, saving model to best_model1.h5\n",
            "\n",
            "Epoch 46: val_loss improved from 0.30924 to 0.30589, saving model to best_model1.h5\n",
            "\n",
            "Epoch 47: val_loss improved from 0.30589 to 0.30213, saving model to best_model1.h5\n",
            "\n",
            "Epoch 48: val_loss improved from 0.30213 to 0.29827, saving model to best_model1.h5\n",
            "\n",
            "Epoch 49: val_loss improved from 0.29827 to 0.29453, saving model to best_model1.h5\n",
            "\n",
            "Epoch 50: val_loss improved from 0.29453 to 0.29087, saving model to best_model1.h5\n",
            "\n",
            "Epoch 51: val_loss improved from 0.29087 to 0.28728, saving model to best_model1.h5\n",
            "\n",
            "Epoch 52: val_loss improved from 0.28728 to 0.28446, saving model to best_model1.h5\n",
            "\n",
            "Epoch 53: val_loss improved from 0.28446 to 0.28207, saving model to best_model1.h5\n",
            "\n",
            "Epoch 54: val_loss improved from 0.28207 to 0.28018, saving model to best_model1.h5\n",
            "\n",
            "Epoch 55: val_loss improved from 0.28018 to 0.27853, saving model to best_model1.h5\n",
            "\n",
            "Epoch 56: val_loss improved from 0.27853 to 0.27731, saving model to best_model1.h5\n",
            "\n",
            "Epoch 57: val_loss improved from 0.27731 to 0.27688, saving model to best_model1.h5\n",
            "\n",
            "Epoch 58: val_loss improved from 0.27688 to 0.27641, saving model to best_model1.h5\n",
            "\n",
            "Epoch 59: val_loss improved from 0.27641 to 0.27599, saving model to best_model1.h5\n",
            "\n",
            "Epoch 60: val_loss improved from 0.27599 to 0.27544, saving model to best_model1.h5\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.27544\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.27544\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.27544\n",
            "\n",
            "Epoch 64: val_loss improved from 0.27544 to 0.27380, saving model to best_model1.h5\n",
            "\n",
            "Epoch 65: val_loss improved from 0.27380 to 0.27132, saving model to best_model1.h5\n",
            "\n",
            "Epoch 66: val_loss improved from 0.27132 to 0.26882, saving model to best_model1.h5\n",
            "\n",
            "Epoch 67: val_loss improved from 0.26882 to 0.26640, saving model to best_model1.h5\n",
            "\n",
            "Epoch 68: val_loss improved from 0.26640 to 0.26442, saving model to best_model1.h5\n",
            "\n",
            "Epoch 69: val_loss improved from 0.26442 to 0.26225, saving model to best_model1.h5\n",
            "\n",
            "Epoch 70: val_loss improved from 0.26225 to 0.26059, saving model to best_model1.h5\n",
            "\n",
            "Epoch 71: val_loss improved from 0.26059 to 0.25979, saving model to best_model1.h5\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.25979\n",
            "\n",
            "Epoch 73: val_loss improved from 0.25979 to 0.25971, saving model to best_model1.h5\n",
            "\n",
            "Epoch 74: val_loss improved from 0.25971 to 0.25916, saving model to best_model1.h5\n",
            "\n",
            "Epoch 75: val_loss improved from 0.25916 to 0.25895, saving model to best_model1.h5\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.25895\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.25895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model1 = load_model(model_path1)\n",
        "best_model1.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkIC_ejet5x1",
        "outputId": "0699fa20-f7c4-4c4e-aa51-dc4561156a9b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3833 - accuracy: 0.8571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3833175003528595, 0.8571428656578064]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 2. 은닉층 4개"
      ],
      "metadata": {
        "id": "ZPpKVMTuwacO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([ \n",
        "    Dense(80, input_dim=60, activation='relu'),\n",
        "    Dense(48, activation='relu'),\n",
        "    Dense(20, activation='relu'),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmCPut0FwQKl",
        "outputId": "c6e8331a-e8db-44fa-91d3-3dbe8dc8aa7d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 80)                4880      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 48)                3888      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                980       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 8)                 168       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,925\n",
            "Trainable params: 9,925\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile('adam', 'binary_crossentropy', ['accuracy'])\n",
        "model_path2 = 'best_model2.h5'\n",
        "mc2 = ModelCheckpoint(filepath=model_path2, verbose=1, save_best_only=True)\n",
        "es2 = EarlyStopping(monitor='val_loss', patience=20)\n",
        "hist2 = model2.fit(X_train, y_train, validation_split=0.2,\n",
        "                   epochs=200, batch_size=100, verbose=0, \n",
        "                   callbacks=[mc2, es2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVBYPdNWw4Jn",
        "outputId": "1f397c64-f2a9-4c27-f61e-10590f567f2a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 0.65999, saving model to best_model2.h5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.65999 to 0.65190, saving model to best_model2.h5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.65190 to 0.64315, saving model to best_model2.h5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.64315 to 0.63315, saving model to best_model2.h5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.63315 to 0.62134, saving model to best_model2.h5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.62134 to 0.60891, saving model to best_model2.h5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.60891 to 0.59569, saving model to best_model2.h5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.59569 to 0.58144, saving model to best_model2.h5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.58144 to 0.56698, saving model to best_model2.h5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.56698 to 0.55316, saving model to best_model2.h5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.55316 to 0.53991, saving model to best_model2.h5\n",
            "\n",
            "Epoch 12: val_loss improved from 0.53991 to 0.52615, saving model to best_model2.h5\n",
            "\n",
            "Epoch 13: val_loss improved from 0.52615 to 0.51245, saving model to best_model2.h5\n",
            "\n",
            "Epoch 14: val_loss improved from 0.51245 to 0.49971, saving model to best_model2.h5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.49971 to 0.48716, saving model to best_model2.h5\n",
            "\n",
            "Epoch 16: val_loss improved from 0.48716 to 0.47338, saving model to best_model2.h5\n",
            "\n",
            "Epoch 17: val_loss improved from 0.47338 to 0.45985, saving model to best_model2.h5\n",
            "\n",
            "Epoch 18: val_loss improved from 0.45985 to 0.44498, saving model to best_model2.h5\n",
            "\n",
            "Epoch 19: val_loss improved from 0.44498 to 0.43062, saving model to best_model2.h5\n",
            "\n",
            "Epoch 20: val_loss improved from 0.43062 to 0.41671, saving model to best_model2.h5\n",
            "\n",
            "Epoch 21: val_loss improved from 0.41671 to 0.40361, saving model to best_model2.h5\n",
            "\n",
            "Epoch 22: val_loss improved from 0.40361 to 0.39123, saving model to best_model2.h5\n",
            "\n",
            "Epoch 23: val_loss improved from 0.39123 to 0.38233, saving model to best_model2.h5\n",
            "\n",
            "Epoch 24: val_loss improved from 0.38233 to 0.37539, saving model to best_model2.h5\n",
            "\n",
            "Epoch 25: val_loss improved from 0.37539 to 0.37087, saving model to best_model2.h5\n",
            "\n",
            "Epoch 26: val_loss improved from 0.37087 to 0.36742, saving model to best_model2.h5\n",
            "\n",
            "Epoch 27: val_loss improved from 0.36742 to 0.36411, saving model to best_model2.h5\n",
            "\n",
            "Epoch 28: val_loss improved from 0.36411 to 0.35896, saving model to best_model2.h5\n",
            "\n",
            "Epoch 29: val_loss improved from 0.35896 to 0.35606, saving model to best_model2.h5\n",
            "\n",
            "Epoch 30: val_loss improved from 0.35606 to 0.35369, saving model to best_model2.h5\n",
            "\n",
            "Epoch 31: val_loss improved from 0.35369 to 0.35105, saving model to best_model2.h5\n",
            "\n",
            "Epoch 32: val_loss improved from 0.35105 to 0.34804, saving model to best_model2.h5\n",
            "\n",
            "Epoch 33: val_loss improved from 0.34804 to 0.34516, saving model to best_model2.h5\n",
            "\n",
            "Epoch 34: val_loss improved from 0.34516 to 0.34202, saving model to best_model2.h5\n",
            "\n",
            "Epoch 35: val_loss improved from 0.34202 to 0.33870, saving model to best_model2.h5\n",
            "\n",
            "Epoch 36: val_loss improved from 0.33870 to 0.33729, saving model to best_model2.h5\n",
            "\n",
            "Epoch 37: val_loss improved from 0.33729 to 0.33653, saving model to best_model2.h5\n",
            "\n",
            "Epoch 38: val_loss improved from 0.33653 to 0.33548, saving model to best_model2.h5\n",
            "\n",
            "Epoch 39: val_loss improved from 0.33548 to 0.33410, saving model to best_model2.h5\n",
            "\n",
            "Epoch 40: val_loss improved from 0.33410 to 0.33397, saving model to best_model2.h5\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.33397\n",
            "\n",
            "Epoch 42: val_loss improved from 0.33397 to 0.33347, saving model to best_model2.h5\n",
            "\n",
            "Epoch 43: val_loss improved from 0.33347 to 0.33199, saving model to best_model2.h5\n",
            "\n",
            "Epoch 44: val_loss improved from 0.33199 to 0.33084, saving model to best_model2.h5\n",
            "\n",
            "Epoch 45: val_loss improved from 0.33084 to 0.32933, saving model to best_model2.h5\n",
            "\n",
            "Epoch 46: val_loss improved from 0.32933 to 0.32881, saving model to best_model2.h5\n",
            "\n",
            "Epoch 47: val_loss improved from 0.32881 to 0.32785, saving model to best_model2.h5\n",
            "\n",
            "Epoch 48: val_loss improved from 0.32785 to 0.32717, saving model to best_model2.h5\n",
            "\n",
            "Epoch 49: val_loss improved from 0.32717 to 0.32668, saving model to best_model2.h5\n",
            "\n",
            "Epoch 50: val_loss improved from 0.32668 to 0.32628, saving model to best_model2.h5\n",
            "\n",
            "Epoch 51: val_loss improved from 0.32628 to 0.32544, saving model to best_model2.h5\n",
            "\n",
            "Epoch 52: val_loss improved from 0.32544 to 0.32460, saving model to best_model2.h5\n",
            "\n",
            "Epoch 53: val_loss improved from 0.32460 to 0.32380, saving model to best_model2.h5\n",
            "\n",
            "Epoch 54: val_loss improved from 0.32380 to 0.32295, saving model to best_model2.h5\n",
            "\n",
            "Epoch 55: val_loss improved from 0.32295 to 0.32272, saving model to best_model2.h5\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.32272\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.32272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model2 = load_model(model_path2)\n",
        "best_model2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUjxAvt7xvGH",
        "outputId": "b621a4f9-8fa5-40e9-87b6-d69de8b57ae6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.8571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49250778555870056, 0.8571428656578064]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 3. 은닉층 6개"
      ],
      "metadata": {
        "id": "uG_rgxcAyAjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Sequential([ \n",
        "    Dense(100, input_dim=60, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(40, activation='relu'),\n",
        "    Dense(20, activation='relu'),\n",
        "    Dense(10, activation='relu'),\n",
        "    Dense(4, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6vO1-Z3xv2G",
        "outputId": "4d0b9106-7ef7-4611-fc6a-db34ba43a2b5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 100)               6100      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                6464      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 40)                2600      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 20)                820       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                210       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,243\n",
            "Trainable params: 16,243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile('adam', 'binary_crossentropy', ['accuracy'])\n",
        "model_path3 = 'best_model3.h5'\n",
        "mc3 = ModelCheckpoint(filepath=model_path3, verbose=1, save_best_only=True)\n",
        "es3 = EarlyStopping(monitor='val_loss', patience=20)\n",
        "hist3 = model3.fit(X_train, y_train, validation_split=0.2,\n",
        "                   epochs=200, batch_size=100, verbose=0, \n",
        "                   callbacks=[mc3, es3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJNgFV0AyYQQ",
        "outputId": "683e4d6a-a97e-4fe5-eca8-73848460cf83"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 82 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff6deac1ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 0.67360, saving model to best_model3.h5\n",
            "\n",
            "Epoch 2: val_loss improved from 0.67360 to 0.65937, saving model to best_model3.h5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.65937 to 0.64619, saving model to best_model3.h5\n",
            "\n",
            "Epoch 4: val_loss improved from 0.64619 to 0.63346, saving model to best_model3.h5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.63346 to 0.62015, saving model to best_model3.h5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.62015 to 0.60404, saving model to best_model3.h5\n",
            "\n",
            "Epoch 7: val_loss improved from 0.60404 to 0.58472, saving model to best_model3.h5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.58472 to 0.56420, saving model to best_model3.h5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.56420 to 0.54450, saving model to best_model3.h5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.54450 to 0.52469, saving model to best_model3.h5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.52469 to 0.50431, saving model to best_model3.h5\n",
            "\n",
            "Epoch 12: val_loss improved from 0.50431 to 0.48229, saving model to best_model3.h5\n",
            "\n",
            "Epoch 13: val_loss improved from 0.48229 to 0.46046, saving model to best_model3.h5\n",
            "\n",
            "Epoch 14: val_loss improved from 0.46046 to 0.43810, saving model to best_model3.h5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.43810 to 0.41522, saving model to best_model3.h5\n",
            "\n",
            "Epoch 16: val_loss improved from 0.41522 to 0.39243, saving model to best_model3.h5\n",
            "\n",
            "Epoch 17: val_loss improved from 0.39243 to 0.36762, saving model to best_model3.h5\n",
            "\n",
            "Epoch 18: val_loss improved from 0.36762 to 0.34708, saving model to best_model3.h5\n",
            "\n",
            "Epoch 19: val_loss improved from 0.34708 to 0.33535, saving model to best_model3.h5\n",
            "\n",
            "Epoch 20: val_loss improved from 0.33535 to 0.32800, saving model to best_model3.h5\n",
            "\n",
            "Epoch 21: val_loss improved from 0.32800 to 0.32635, saving model to best_model3.h5\n",
            "\n",
            "Epoch 22: val_loss improved from 0.32635 to 0.32284, saving model to best_model3.h5\n",
            "\n",
            "Epoch 23: val_loss improved from 0.32284 to 0.31654, saving model to best_model3.h5\n",
            "\n",
            "Epoch 24: val_loss improved from 0.31654 to 0.31433, saving model to best_model3.h5\n",
            "\n",
            "Epoch 25: val_loss improved from 0.31433 to 0.31400, saving model to best_model3.h5\n",
            "\n",
            "Epoch 26: val_loss improved from 0.31400 to 0.31309, saving model to best_model3.h5\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.31309\n",
            "\n",
            "Epoch 28: val_loss improved from 0.31309 to 0.31146, saving model to best_model3.h5\n",
            "\n",
            "Epoch 29: val_loss improved from 0.31146 to 0.30672, saving model to best_model3.h5\n",
            "\n",
            "Epoch 30: val_loss improved from 0.30672 to 0.30038, saving model to best_model3.h5\n",
            "\n",
            "Epoch 31: val_loss improved from 0.30038 to 0.29647, saving model to best_model3.h5\n",
            "\n",
            "Epoch 32: val_loss improved from 0.29647 to 0.29137, saving model to best_model3.h5\n",
            "\n",
            "Epoch 33: val_loss improved from 0.29137 to 0.28383, saving model to best_model3.h5\n",
            "\n",
            "Epoch 34: val_loss improved from 0.28383 to 0.27817, saving model to best_model3.h5\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.27817\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.27817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model3 = load_model(model_path3)\n",
        "best_model3.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZiNM5EnypbA",
        "outputId": "343f17c7-bdcc-43a3-a5a9-78a25d2ec284"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.8810\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47107401490211487, 0.8809523582458496]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cPAUtPaAyy1e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}